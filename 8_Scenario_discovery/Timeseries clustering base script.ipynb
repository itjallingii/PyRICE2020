{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from ema_workbench.analysis import parcoords\n",
    "from ema_workbench.analysis import clusterer, plotting, Density\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from ema_workbench import save_results, load_results\n",
    "from ema_workbench.analysis import clusterer, plotting, Density\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import dataframe_image as dfi\n",
    "os.chdir(os.getcwd())\n",
    "import sys\n",
    "\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "#pydice_folder = os.path.dirname(os.getcwd()) + \"\\\\1_Model\"\n",
    "#sys.path.insert(1, pydice_folder)\n",
    "\n",
    "from ema_workbench import (save_results)\n",
    "from ema_workbench import (perform_experiments, Model, Policy, RealParameter, \n",
    "                           IntegerParameter, ScalarOutcome, ema_logging, MultiprocessingEvaluator)\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short term time series clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints_to_save = np.arange(2005,2105+10,10)\n",
    "\n",
    "#objectives_list_timeseries_name = ['Damages ','Utility ',\n",
    "#                        'Lowest income per capita ','Highest climate impact per capita ',\n",
    "#                        'Distance to treshold ','Population under treshold ',\n",
    "#                        'Intratemporal utility GINI ','Intratemporal impact GINI ',\n",
    "#                        'Atmospheric Temperature ', 'Industrial Emission ', 'Total Output ']\n",
    "\n",
    "\n",
    "objectives_list_timeseries_name =  ['Intratemporal utility GINI ','Intratemporal impact GINI ']\n",
    "\n",
    "supplementary_list_timeseries_name = ['CPC ','Population ']\n",
    "supplementary_list_quintile_name = ['CPC pre damage ','CPC post damage ']\n",
    "\n",
    "outcomes = []\n",
    "for name in objectives_list_timeseries_name:\n",
    "    for year in timepoints_to_save:\n",
    "        name_year = name + str(year)\n",
    "        outcomes.append(name_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints_to_save = np.arange(2005,2105+10,10)                          \n",
    "#objectives_list_timeseries_name =  {'egal':['Intratemporal utility GINI ','Intratemporal impact GINI '],\n",
    "#                                    'util':['Utility ','Damages GINI '],\n",
    "#                                    'prio':['Lowest income per capita','Highest climate impact per capita' ],\n",
    "#                                    'suff':['Population under treshold','Distance to treshold',] }\n",
    "\n",
    "objectives_list_timeseries_name =  ['Intratemporal utility GINI ','Intratemporal impact GINI ',\n",
    "                                    'Utility ','Damages ','Lowest income per capita ',\n",
    "                                    'Highest climate impact per capita ',\n",
    "                                    'Population under treshold ','Distance to treshold ' ]\n",
    "\n",
    "policy_list = [\"Egal_policy36\",\"Prio_policy28\",\"Util_policy370\",\"Suff_policy30\"]\n",
    "\n",
    "for index in range(0,2):\n",
    "    policy_selected = policy_list[index]\n",
    "    cluster_data_35k = results_total_short_term[results_total_short_term['policy_recoded'] == policy_selected]\n",
    "    data = cluster_data_35k.to_numpy() \n",
    "    \n",
    "    #randomly select 15000 timeseries for clustering\n",
    "    rows = np.array(list(range(500)))\n",
    "    np.random.seed(0)\n",
    "    selected_series = np.random.choice(rows, size=500, replace=False)\n",
    "    \n",
    "    #get input data with select rows\n",
    "    cluster_data_15k = data[selected_series]\n",
    "    \n",
    "    #construct original input dataframe with only rows from random selection (15k)\n",
    "    input_data_15k = pd.DataFrame(data=cluster_data_15k,columns= cluster_data_35k.columns)\n",
    "    input_data_15k = input_data_15k.set_index(input_data_15k.columns[0])\n",
    "    \n",
    "    #construct experiment dataframe with only scenario and policy columns\n",
    "    experiments = input_data_15k.iloc[:,0:17]\n",
    "    \n",
    "    for objective in objectives_list_timeseries_name:\n",
    "        outcomes = []\n",
    "        for year in timepoints_to_save:\n",
    "                name_year = objective + str(year)\n",
    "                outcomes.append(name_year)\n",
    "\n",
    "        data = input_data_15k[outcomes].to_numpy(dtype =float)\n",
    "        #data = data.float()\n",
    "                \n",
    "        start = time.time()\n",
    "        distances = clusterer.calculate_cid(data)\n",
    "                \n",
    "        #np.save('TSC_30k_scen_damages_distances', distances)\n",
    "        end = time.time()\n",
    "        print('Cluster time is ' + str(round((end - start))) + ' secondes')\n",
    "        print(\"\")\n",
    "        \n",
    "        #calculate silhouette width\n",
    "        sil_score_lst = []\n",
    "        start = time.time()\n",
    "        for n_clusters in range(2,11):\n",
    "            clusterers = AgglomerativeClustering(n_clusters=n_clusters, affinity='precomputed', linkage=\"complete\")\n",
    "            cluster_labels = clusterers.fit_predict(distances)\n",
    "            silhouette_avg = silhouette_score(distances, cluster_labels, metric=\"precomputed\")\n",
    "            sil_score_lst.append(silhouette_avg)\n",
    "            \n",
    "            print(objective + \"_\" + policy_selected + \": For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n",
    "        \n",
    "        end = time.time()\n",
    "        print(\"\")        \n",
    "        print('Silhouette time is ' + str(round((end - start)/60)) + ' minutes')\n",
    "\n",
    "        with open(objective + \"_\" + policy_selected + '_cluster_silhouette_width.txt', 'w') as f:\n",
    "            for s in sil_score_lst:\n",
    "                f.write(str(s) + \"\\n\")\n",
    "                \n",
    "        #do agglomerative clustering on the distances\n",
    "        start = time.time()\n",
    "        for j in range(2, 8):\n",
    "            clusters = clusterer.apply_agglomerative_clustering(distances,n_clusters=j)\n",
    "            x = experiments.copy()\n",
    "            x['clusters'] = clusters.astype('object')\n",
    "            x.to_csv('TSC_35k_' + objective + \"_\" + policy_selected + '_cluster_' + str(j) + '.csv')\n",
    "        end = time.time()\n",
    "        print('Agglomerative clustering time is ' + str(round((end - start) / 60)) + ' minutes')\n",
    "        print(\"\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
