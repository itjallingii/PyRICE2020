{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local path in PyRICE = \n",
      "C:\\Users\\ivart\\OneDrive\\Bureaublad\\Afstuderen\\WRR\\PyRICE Ivar Tjallingii\\PyRICE2020\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import norm, skewnorm, cauchy, lognorm\n",
    "import logging\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "pydice_folder = os.path.dirname(os.getcwd())\n",
    "\n",
    "print('local path in PyRICE = ')\n",
    "print(pydice_folder)\n",
    "\n",
    "sys.path.append(pydice_folder)\n",
    "\n",
    "\n",
    "class PyRICE(object):\n",
    "    \"\"\" RICE simulation model:\n",
    "        tstep: time step/interval\n",
    "        steps: amount of years looking into the future\n",
    "        model_specification: model specification for 'EMA_det', 'EMA_dist' or 'Validation'  \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting line-profiler\n",
      "  Using cached line_profiler-3.1.0.tar.gz (45 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: IPython in c:\\users\\ivart\\anaconda3\\lib\\site-packages (from line-profiler) (7.19.0)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\ivart\\anaconda3\\lib\\site-packages (from IPython->line-profiler) (0.17.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\ivart\\anaconda3\\lib\\site-packages (from IPython->line-profiler) (0.2.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\ivart\\anaconda3\\lib\\site-packages (from IPython->line-profiler) (2.7.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\ivart\\anaconda3\\lib\\site-packages (from IPython->line-profiler) (50.3.1.post20201107)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\ivart\\anaconda3\\lib\\site-packages (from IPython->line-profiler) (3.0.8)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\ivart\\anaconda3\\lib\\site-packages (from IPython->line-profiler) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\users\\ivart\\anaconda3\\lib\\site-packages (from IPython->line-profiler) (4.4.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\ivart\\anaconda3\\lib\\site-packages (from IPython->line-profiler) (5.0.5)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\ivart\\anaconda3\\lib\\site-packages (from IPython->line-profiler) (0.7.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\ivart\\anaconda3\\lib\\site-packages (from jedi>=0.10->IPython->line-profiler) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ivart\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->line-profiler) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\ivart\\anaconda3\\lib\\site-packages (from traitlets>=4.2->IPython->line-profiler) (0.2.0)\n",
      "Building wheels for collected packages: line-profiler\n",
      "  Building wheel for line-profiler (PEP 517): started\n",
      "  Building wheel for line-profiler (PEP 517): finished with status 'error'\n",
      "Failed to build line-profiler\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\ivart\\anaconda3\\python.exe' 'C:\\Users\\ivart\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py' build_wheel 'C:\\Users\\ivart\\AppData\\Local\\Temp\\tmpat3j9k1f'\n",
      "       cwd: C:\\Users\\ivart\\AppData\\Local\\Temp\\pip-install-fbrjio8k\\line-profiler\n",
      "  Complete output (162 lines):\n",
      "  Not searching for unused variables given on the command line.\n",
      "  -- The C compiler identification is unknown\n",
      "  CMake Error at CMakeLists.txt:3 (ENABLE_LANGUAGE):\n",
      "    No CMAKE_C_COMPILER could be found.\n",
      "  \n",
      "    Tell CMake where to find the compiler by setting either the environment\n",
      "    variable \"CC\" or the CMake cache entry CMAKE_C_COMPILER to the full path to\n",
      "    the compiler, or to the compiler name if it is in the PATH.\n",
      "  \n",
      "  \n",
      "  -- Configuring incomplete, errors occurred!\n",
      "  See also \"C:/Users/ivart/AppData/Local/Temp/pip-install-fbrjio8k/line-profiler/_cmake_test_compile/build/CMakeFiles/CMakeOutput.log\".\n",
      "  See also \"C:/Users/ivart/AppData/Local/Temp/pip-install-fbrjio8k/line-profiler/_cmake_test_compile/build/CMakeFiles/CMakeError.log\".\n",
      "  Not searching for unused variables given on the command line.\n",
      "  CMake Error at CMakeLists.txt:2 (PROJECT):\n",
      "    Generator\n",
      "  \n",
      "      Visual Studio 15 2017 Win64\n",
      "  \n",
      "    could not find any instance of Visual Studio.\n",
      "  \n",
      "  \n",
      "  \n",
      "  -- Configuring incomplete, errors occurred!\n",
      "  See also \"C:/Users/ivart/AppData/Local/Temp/pip-install-fbrjio8k/line-profiler/_cmake_test_compile/build/CMakeFiles/CMakeOutput.log\".\n",
      "  Not searching for unused variables given on the command line.\n",
      "  -- The C compiler identification is unknown\n",
      "  CMake Error at CMakeLists.txt:3 (ENABLE_LANGUAGE):\n",
      "    The CMAKE_C_COMPILER:\n",
      "  \n",
      "      cl\n",
      "  \n",
      "    is not a full path and was not found in the PATH.\n",
      "  \n",
      "    To use the NMake generator with Visual C++, cmake must be run from a shell\n",
      "    that can use the compiler cl from the command line.  This environment is\n",
      "    unable to invoke the cl compiler.  To fix this problem, run cmake from the\n",
      "    Visual Studio Command Prompt (vcvarsall.bat).\n",
      "  \n",
      "    Tell CMake where to find the compiler by setting either the environment\n",
      "    variable \"CC\" or the CMake cache entry CMAKE_C_COMPILER to the full path to\n",
      "    the compiler, or to the compiler name if it is in the PATH.\n",
      "  \n",
      "  \n",
      "  -- Configuring incomplete, errors occurred!\n",
      "  See also \"C:/Users/ivart/AppData/Local/Temp/pip-install-fbrjio8k/line-profiler/_cmake_test_compile/build/CMakeFiles/CMakeOutput.log\".\n",
      "  See also \"C:/Users/ivart/AppData/Local/Temp/pip-install-fbrjio8k/line-profiler/_cmake_test_compile/build/CMakeFiles/CMakeError.log\".\n",
      "  Not searching for unused variables given on the command line.\n",
      "  -- The C compiler identification is unknown\n",
      "  CMake Error at CMakeLists.txt:3 (ENABLE_LANGUAGE):\n",
      "    The CMAKE_C_COMPILER:\n",
      "  \n",
      "      cl\n",
      "  \n",
      "    is not a full path and was not found in the PATH.\n",
      "  \n",
      "    To use the JOM generator with Visual C++, cmake must be run from a shell\n",
      "    that can use the compiler cl from the command line.  This environment is\n",
      "    unable to invoke the cl compiler.  To fix this problem, run cmake from the\n",
      "    Visual Studio Command Prompt (vcvarsall.bat).\n",
      "  \n",
      "    Tell CMake where to find the compiler by setting either the environment\n",
      "    variable \"CC\" or the CMake cache entry CMAKE_C_COMPILER to the full path to\n",
      "    the compiler, or to the compiler name if it is in the PATH.\n",
      "  \n",
      "  \n",
      "  -- Configuring incomplete, errors occurred!\n",
      "  See also \"C:/Users/ivart/AppData/Local/Temp/pip-install-fbrjio8k/line-profiler/_cmake_test_compile/build/CMakeFiles/CMakeOutput.log\".\n",
      "  See also \"C:/Users/ivart/AppData/Local/Temp/pip-install-fbrjio8k/line-profiler/_cmake_test_compile/build/CMakeFiles/CMakeError.log\".\n",
      "  \n",
      "  \n",
      "  --------------------------------------------------------------------------------\n",
      "  -- Trying \"Ninja (Visual Studio 15 2017 Win64 v141)\" generator\n",
      "  --------------------------------\n",
      "  ---------------------------\n",
      "  ----------------------\n",
      "  -----------------\n",
      "  ------------\n",
      "  -------\n",
      "  --\n",
      "  --\n",
      "  -------\n",
      "  ------------\n",
      "  -----------------\n",
      "  ----------------------\n",
      "  ---------------------------\n",
      "  --------------------------------\n",
      "  -- Trying \"Ninja (Visual Studio 15 2017 Win64 v141)\" generator - failure\n",
      "  --------------------------------------------------------------------------------\n",
      "  \n",
      "  \n",
      "  \n",
      "  --------------------------------------------------------------------------------\n",
      "  -- Trying \"Visual Studio 15 2017 Win64 v141\" generator\n",
      "  --------------------------------\n",
      "  ---------------------------\n",
      "  ----------------------\n",
      "  -----------------\n",
      "  ------------\n",
      "  -------\n",
      "  --\n",
      "  --\n",
      "  -------\n",
      "  ------------\n",
      "  -----------------\n",
      "  ----------------------\n",
      "  ---------------------------\n",
      "  --------------------------------\n",
      "  -- Trying \"Visual Studio 15 2017 Win64 v141\" generator - failure\n",
      "  --------------------------------------------------------------------------------\n",
      "  \n",
      "  \n",
      "  \n",
      "  --------------------------------------------------------------------------------\n",
      "  -- Trying \"NMake Makefiles (Visual Studio 15 2017 Win64 v141)\" generator\n",
      "  --------------------------------\n",
      "  ---------------------------\n",
      "  ----------------------\n",
      "  -----------------\n",
      "  ------------\n",
      "  -------\n",
      "  --\n",
      "  --\n",
      "  -------\n",
      "  ------------\n",
      "  -----------------\n",
      "  ----------------------\n",
      "  ---------------------------\n",
      "  --------------------------------\n",
      "  -- Trying \"NMake Makefiles (Visual Studio 15 2017 Win64 v141)\" generator - failure\n",
      "  --------------------------------------------------------------------------------\n",
      "  \n",
      "  \n",
      "  \n",
      "  --------------------------------------------------------------------------------\n",
      "  -- Trying \"NMake Makefiles JOM (Visual Studio 15 2017 Win64 v141)\" generator\n",
      "  --------------------------------\n",
      "  ---------------------------\n",
      "  ----------------------\n",
      "  -----------------\n",
      "  ------------\n",
      "  -------\n",
      "  --\n",
      "  --\n",
      "  -------\n",
      "  ------------\n",
      "  -----------------\n",
      "  ----------------------\n",
      "  ---------------------------\n",
      "  --------------------------------\n",
      "  -- Trying \"NMake Makefiles JOM (Visual Studio 15 2017 Win64 v141)\" generator - failure\n",
      "  --------------------------------------------------------------------------------\n",
      "  \n",
      "  ********************************************************************************\n",
      "  scikit-build could not get a working generator for your system. Aborting build.\n",
      "  \n",
      "  Building windows wheels for Python 3.8 requires Microsoft Visual Studio 2017.\n",
      "  Get it with \"Visual Studio 2017\":\n",
      "  \n",
      "    https://visualstudio.microsoft.com/vs/\n",
      "  \n",
      "  ********************************************************************************\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for line-profiler\n",
      "ERROR: Could not build wheels for line-profiler which use PEP 517 and cannot be installed directly\n"
     ]
    }
   ],
   "source": [
    "pip install line-profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "RICE_input = pd.read_excel(\"input_data_RICE.xlsx\")\n",
    "region_pop_gr = RICE_input.iloc[0:12,1:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17851791916683227, 0.20441168561441803, 0.20081130743596862,\n",
       "        0.19862347859815724, 0.19724517955141138, 0.19749773378886082,\n",
       "        0.19978659099475396, 0.20224864393886471, 0.2050013318659679,\n",
       "        0.20701315102347004, 0.20687069210728645, 0.2203030788597251,\n",
       "        0.2203030788597251, 0.2203030788597251, 0.2203030788597251,\n",
       "        0.2203030788597251, 0.2203030788597251, 0.2203030788597251,\n",
       "        0.2203030788597251, 0.2203030788597251, 0.2203030788597251,\n",
       "        0.2203030788597251, 0.2203030788597251, 0.2203030788597251,\n",
       "        0.2203030788597251, 0.2203030788597251, 0.2203030788597251,\n",
       "        0.2203030788597251, 0.2203030788597251, 0.2203030788597251,\n",
       "        0.2203030788597251],\n",
       "       [0.17464278549877818, 0.19951187573456713, 0.19621702705844843,\n",
       "        0.19444764809439508, 0.1931176968788147, 0.1934203792856198,\n",
       "        0.19499881757129625, 0.19675155944103084, 0.1986775404241552,\n",
       "        0.20517684580955442, 0.21074492696069239, 0.2203362818132277,\n",
       "        0.2203362818132277, 0.2203362818132277, 0.2203362818132277,\n",
       "        0.2203362818132277, 0.2203362818132277, 0.2203362818132277,\n",
       "        0.2203362818132277, 0.2203362818132277, 0.2203362818132277,\n",
       "        0.2203362818132277, 0.2203362818132277, 0.2203362818132277,\n",
       "        0.2203362818132277, 0.2203362818132277, 0.2203362818132277,\n",
       "        0.2203362818132277, 0.2203362818132277, 0.2203362818132277,\n",
       "        0.2203362818132277],\n",
       "       [0.15130516850935352, 0.18028879870424402, 0.17561051284600046,\n",
       "        0.16834939682036698, 0.17936264615265576, 0.18715052917114447,\n",
       "        0.18886752273284263, 0.19078953271553145, 0.1929954376999791,\n",
       "        0.20201478435586034, 0.20937148693838403, 0.22226937429570431,\n",
       "        0.22226937429570431, 0.22226937429570431, 0.22226937429570431,\n",
       "        0.22226937429570431, 0.22226937429570431, 0.22226937429570431,\n",
       "        0.22226937429570431, 0.22226937429570431, 0.22226937429570431,\n",
       "        0.22226937429570431, 0.22226937429570431, 0.22226937429570431,\n",
       "        0.22226937429570431, 0.22226937429570431, 0.22226937429570431,\n",
       "        0.22226937429570431, 0.22226937429570431, 0.22226937429570431,\n",
       "        0.22226937429570431],\n",
       "       [0.19116870416633872, 0.18903154012827164, 0.18513371193962028,\n",
       "        0.185563870068611, 0.1878739277780751, 0.1898911896439817,\n",
       "        0.1906481317971881, 0.19168340007296758, 0.19308059868291075,\n",
       "        0.20313479711589796, 0.21241990984042894, 0.22223322828967537,\n",
       "        0.22223322828967537, 0.22223322828967537, 0.22223322828967537,\n",
       "        0.22223322828967537, 0.22223322828967537, 0.22223322828967537,\n",
       "        0.22223322828967537, 0.22223322828967537, 0.22223322828967537,\n",
       "        0.22223322828967537, 0.22223322828967537, 0.22223322828967537,\n",
       "        0.22223322828967537, 0.22223322828967537, 0.22223322828967537,\n",
       "        0.22223322828967537, 0.22223322828967537, 0.22223322828967537,\n",
       "        0.22223322828967537],\n",
       "       [0.1950068390972948, 0.22579565828348314, 0.21818997077859106,\n",
       "        0.2137651998818286, 0.2110399666476615, 0.2105428563367011,\n",
       "        0.21015163132466624, 0.2101639619273628, 0.21067751414477806,\n",
       "        0.21679424846015824, 0.22273954697694098, 0.22890898798344628,\n",
       "        0.22890898798344628, 0.22890898798344628, 0.22890898798344628,\n",
       "        0.22890898798344628, 0.22890898798344628, 0.22890898798344628,\n",
       "        0.22890898798344628, 0.22890898798344628, 0.22890898798344628,\n",
       "        0.22890898798344628, 0.22890898798344628, 0.22890898798344628,\n",
       "        0.22890898798344628, 0.22890898798344628, 0.22890898798344628,\n",
       "        0.22890898798344628, 0.22890898798344628, 0.22890898798344628,\n",
       "        0.22890898798344628],\n",
       "       [0.3570814418629139, 0.2267610075161593, 0.21516476481009253,\n",
       "        0.20754873475224947, 0.2032796927112448, 0.20375853404594946,\n",
       "        0.2034237446652743, 0.20334246847133677, 0.2031673021727247,\n",
       "        0.20922027492066747, 0.2185201157729674, 0.21324434378424598,\n",
       "        0.21324434378424598, 0.21324434378424598, 0.21324434378424598,\n",
       "        0.21324434378424598, 0.21324434378424598, 0.21324434378424598,\n",
       "        0.21324434378424598, 0.21324434378424598, 0.21324434378424598,\n",
       "        0.21324434378424598, 0.21324434378424598, 0.21324434378424598,\n",
       "        0.21324434378424598, 0.21324434378424598, 0.21324434378424598,\n",
       "        0.21324434378424598, 0.21324434378424598, 0.21324434378424598,\n",
       "        0.21324434378424598],\n",
       "       [0.2948464854719452, 0.26865630507701344, 0.2537335415937801,\n",
       "        0.24344426015069293, 0.23218356885139413, 0.22645882046122337,\n",
       "        0.22526327943248856, 0.22454207112988211, 0.22439286463993957,\n",
       "        0.22474462158787176, 0.2257286207432846, 0.22819109400760584,\n",
       "        0.22819109400760584, 0.22819109400760584, 0.22819109400760584,\n",
       "        0.22819109400760584, 0.22819109400760584, 0.22819109400760584,\n",
       "        0.22819109400760584, 0.22819109400760584, 0.22819109400760584,\n",
       "        0.22819109400760584, 0.22819109400760584, 0.22819109400760584,\n",
       "        0.22819109400760584, 0.22819109400760584, 0.22819109400760584,\n",
       "        0.22819109400760584, 0.22819109400760584, 0.22819109400760584,\n",
       "        0.22819109400760584],\n",
       "       [0.2570019107911036, 0.25015233122002567, 0.23912167732660797,\n",
       "        0.2307269307031766, 0.22098172984734518, 0.21762884050424672,\n",
       "        0.21845420685757083, 0.2195543374105695, 0.22101455180104704,\n",
       "        0.21586229093181117, 0.20942696512827097, 0.21875518829498314,\n",
       "        0.21875518829498314, 0.21875518829498314, 0.21875518829498314,\n",
       "        0.21875518829498314, 0.21875518829498314, 0.21875518829498314,\n",
       "        0.21875518829498314, 0.21875518829498314, 0.21875518829498314,\n",
       "        0.21875518829498314, 0.21875518829498314, 0.21875518829498314,\n",
       "        0.21875518829498314, 0.21875518829498314, 0.21875518829498314,\n",
       "        0.21875518829498314, 0.21875518829498314, 0.21875518829498314,\n",
       "        0.21875518829498314],\n",
       "       [0.2978886094094431, 0.3035907751484878, 0.28874202541933247,\n",
       "        0.2759362935816252, 0.2561328045055854, 0.2440148149678612,\n",
       "        0.242565811339296, 0.2415283379978714, 0.24092324736913098,\n",
       "        0.2320215868160172, 0.22490582720354135, 0.22378231772835322,\n",
       "        0.22378231772835322, 0.22378231772835322, 0.22378231772835322,\n",
       "        0.22378231772835322, 0.22378231772835322, 0.22378231772835322,\n",
       "        0.22378231772835322, 0.22378231772835322, 0.22378231772835322,\n",
       "        0.22378231772835322, 0.22378231772835322, 0.22378231772835322,\n",
       "        0.22378231772835322, 0.22378231772835322, 0.22378231772835322,\n",
       "        0.22378231772835322, 0.22378231772835322, 0.22378231772835322,\n",
       "        0.22378231772835322],\n",
       "       [0.23570388608045523, 0.23790902069559233, 0.22912270211317867,\n",
       "        0.22069701683870002, 0.21416107983063631, 0.21272081789222094,\n",
       "        0.21309603865646073, 0.21378594238336635, 0.21491052039196434,\n",
       "        0.21680028128984263, 0.2176455679335466, 0.226187871702172,\n",
       "        0.226187871702172, 0.226187871702172, 0.226187871702172,\n",
       "        0.226187871702172, 0.226187871702172, 0.226187871702172,\n",
       "        0.226187871702172, 0.226187871702172, 0.226187871702172,\n",
       "        0.226187871702172, 0.226187871702172, 0.226187871702172,\n",
       "        0.226187871702172, 0.226187871702172, 0.226187871702172,\n",
       "        0.226187871702172, 0.226187871702172, 0.226187871702172,\n",
       "        0.226187871702172],\n",
       "       [0.1869085525402676, 0.20306631580236426, 0.19794957414301073,\n",
       "        0.19302617707505698, 0.189949917891698, 0.18934598039742812,\n",
       "        0.19102341169229398, 0.19285651886479005, 0.1947992496136097,\n",
       "        0.20167915075617232, 0.20770716072191683, 0.2169109006093904,\n",
       "        0.2169109006093904, 0.2169109006093904, 0.2169109006093904,\n",
       "        0.2169109006093904, 0.2169109006093904, 0.2169109006093904,\n",
       "        0.2169109006093904, 0.2169109006093904, 0.2169109006093904,\n",
       "        0.2169109006093904, 0.2169109006093904, 0.2169109006093904,\n",
       "        0.2169109006093904, 0.2169109006093904, 0.2169109006093904,\n",
       "        0.2169109006093904, 0.2169109006093904, 0.2169109006093904,\n",
       "        0.2169109006093904],\n",
       "       [0.24090677874281113, 0.27878900739472695, 0.26593412796489785,\n",
       "        0.25432500497917565, 0.24142114405066595, 0.234531350503117,\n",
       "        0.23295198667090264, 0.23183169833643794, 0.2312447111986669,\n",
       "        0.22879016682325784, 0.22945447097309063, 0.22371270831332768,\n",
       "        0.22371270831332768, 0.22371270831332768, 0.22371270831332768,\n",
       "        0.22371270831332768, 0.22371270831332768, 0.22371270831332768,\n",
       "        0.22371270831332768, 0.22371270831332768, 0.22371270831332768,\n",
       "        0.22371270831332768, 0.22371270831332768, 0.22371270831332768,\n",
       "        0.22371270831332768, 0.22371270831332768, 0.22371270831332768,\n",
       "        0.22371270831332768, 0.22371270831332768, 0.22371270831332768,\n",
       "        0.22371270831332768]], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miu_opt_series = RICE_input.iloc[15:27,1:].to_numpy()\n",
    "sr_opt_series = RICE_input.iloc[30:42,1:].to_numpy()\n",
    "sr_opt_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_series = pd.read_excel(\"RICE_2010_opt_000.xlsm\", sheet_name=\"Validation series\")\n",
    "\n",
    "#get lever series for RICE optimal run\n",
    "miu_opt_series = validation_series.iloc[6:18,3:34].to_numpy() \n",
    "sr_opt_series = validation_series.iloc[21:33,3:34].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01, 0.15],\n",
       "       [-0.03, 0.25],\n",
       "       [0, 0.17],\n",
       "       [0, 0.12],\n",
       "       [0, 0.13],\n",
       "       [-0.11, 0.47],\n",
       "       [0.43, 0.18],\n",
       "       [0.25, 0.2],\n",
       "       [0.2, 0.36],\n",
       "       [0.06, 0.14],\n",
       "       [-0.04, 0.29],\n",
       "       [0.11, 0.21]], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damage_parameters_slr_fit =  RICE_input.iloc[61:73,1:3]\n",
    "damage_parameters_slr_fit = damage_parameters_slr_fit.to_numpy()\n",
    "damage_parameters_slr_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01, 0.15],\n",
       "       [-0.03, 0.25],\n",
       "       [0, 0.17],\n",
       "       [0, 0.12],\n",
       "       [0, 0.13],\n",
       "       [-0.11, 0.47],\n",
       "       [0.43, 0.18],\n",
       "       [0.25, 0.2],\n",
       "       [0.2, 0.36],\n",
       "       [0.06, 0.14],\n",
       "       [-0.04, 0.29],\n",
       "       [0.11, 0.21]], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damage_parameters_slr_fit = pd.read_excel(\"RICE_2010_opt_000.xlsm\", sheet_name=\"SLR fitted parameters\")\n",
    "damage_parameters_slr_fit = damage_parameters_slr_fit.iloc[27:39,13:15].to_numpy()\n",
    "damage_parameters_slr_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting simulation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile simulation.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import norm, skewnorm, cauchy, lognorm\n",
    "import logging\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "def run(tstep=10, steps=31, model_specification=\"Validation_1\",fdamage = 0,welfare_function=\"utilitarian\"):\n",
    "    \n",
    "    pydice_folder = os.path.dirname(os.getcwd())\n",
    "\n",
    "\n",
    "    sys.path.append(pydice_folder)\n",
    "\n",
    "\n",
    "    tstep = tstep # (in years)\n",
    "    steps = steps\n",
    "    tperiod = []\n",
    "    startYear = 2005\n",
    "    model_specification = model_specification\n",
    "    fdamage = fdamage\n",
    "    welfare_function = welfare_function\n",
    "\n",
    "\n",
    "    ########################## SAMPLING OF DAMAGE FUNCTIONS ##########################\n",
    "\n",
    "\n",
    "    #arrange simulation timeline\n",
    "    for i in range(0, steps):\n",
    "        tperiod.append((i*tstep)+startYear)\n",
    "\n",
    "    #setup of json file to store model results\n",
    "    with open(pydice_folder + '\\\\ecs_dist_v5.json') as f:\n",
    "        d=json.load(f)\n",
    "\n",
    "    #setting up three distributions for the climate sensitivity; normal lognormal and gauchy\n",
    "\n",
    "    #creating a list from the dist of t2xC02\n",
    "    np.random.seed(10)\n",
    "\n",
    "    minb = 0\n",
    "    maxb = 20\n",
    "    nsamples = 1000\n",
    "\n",
    "    samples_norm = np.zeros((0,))\n",
    "    while samples_norm.shape[0] < nsamples:\n",
    "        samples = (norm.rvs(d['norm'][0],d['norm'][1],nsamples))\n",
    "        accepted = samples[(samples >= minb) & (samples <= maxb)]\n",
    "        samples_norm = np.concatenate((samples_norm, accepted), axis=0)\n",
    "    samples_norm = samples_norm[:nsamples]\n",
    "\n",
    "    samples_lognorm = np.zeros((0,))\n",
    "    while samples_lognorm.shape[0] < nsamples:\n",
    "        samples = (lognorm.rvs(d['lognorm'][0],d['lognorm'][1],d['lognorm'][2],nsamples))\n",
    "        accepted = samples[(samples >= minb) & (samples <= maxb)]\n",
    "        samples_lognorm = np.concatenate((samples_lognorm, accepted), axis=0)\n",
    "    samples_lognorm = samples_lognorm[:nsamples]\n",
    "\n",
    "    samples_cauchy = np.zeros((0,))\n",
    "    while samples_cauchy.shape[0] < nsamples:\n",
    "        samples = (cauchy.rvs(d['cauchy'][0],d['cauchy'][1],nsamples))\n",
    "        accepted = samples[(samples >= minb) & (samples <= maxb)]\n",
    "        samples_cauchy = np.concatenate((samples_cauchy, accepted), axis=0)\n",
    "    samples_cauchy = samples_cauchy[:nsamples]\n",
    "\n",
    "    # extend array with the deterministic value of the nordhau\n",
    "    samples_norm = np.append(samples_norm, 3.2)\n",
    "    samples_lognorm = np.append(samples_lognorm, 3.2)\n",
    "    samples_cauchy = np.append(samples_cauchy, 3.2)\n",
    "\n",
    "    samples_t2xco2 = [samples_norm, samples_lognorm, samples_cauchy]\n",
    "\n",
    "    #controls for distributive principles\n",
    "    #prioritarian controls \n",
    "    growth_factor_prio = 1.02**10        #how much the worst-off consumption needs to grow each timestep to allow discounting\n",
    "    prioritarian_discounting = \"conditional discounting\"   # no discounting or conditional_growth\n",
    "\n",
    "\n",
    "    #sufficitarian controls\n",
    "    sufficitarian_discounting = \"inheritance discounting\"\n",
    "    growth_factor_suf = 1.02\n",
    "    ini_suf_treshold = 711.75  #based on the poverty line of 1.95 dollar per day \n",
    "\n",
    "    #egalitarian controls\n",
    "    egalitarian_temporal = \"\"\n",
    "    egalitarian_discounting = \"temporal egalitarity\"\n",
    "\n",
    "\n",
    "    #uncertainties from Nordhaus(2010) (first draft)\n",
    "    t2xco2_index = -1\n",
    "    t2xco2_dist = 0\n",
    "    fosslim =6000\n",
    "\n",
    "    #SSP uncertainties\n",
    "    scenario_pop_gdp = 0    #base RICE2010 scenario\n",
    "    scenario_sigma = 0  #base RICE2010 scenario\n",
    "    scenario_cback = 0  #base RICE2010 scenario\n",
    "\n",
    "    #additonal uncertainty for backstop technology to zero emmissions               \n",
    "    #cback_to_zero',0,1),\n",
    "\n",
    "\n",
    "    #decl_back_gr=0.025         \n",
    "\n",
    "    sr = 0.249          # Savings rate is very different for every region --> how to implement in non optimized RICE?\n",
    "\n",
    "    periodfullpart=7      #in OPT RICE period full part is 2075\n",
    "    miu_period=13          #2155 in RICE opt scenario when global emissions are near zero\n",
    "    limmiu=1   #Upper limit on control rate after 2150, in RICE 1 \n",
    "    fdamage=0   #0 is original damage function in RICE 1 is fitted SLR BUILT IN SHAJEE DAMAGE FUNCTIONS\n",
    "    irstp = 0.015   # Initial rate of social time preference (per year) (0.015) (RICE2010 OPT))     \n",
    "\n",
    "    \"\"\"\n",
    "    ######################## INITIALIZE DATA IMPORTS ########################\n",
    "    \"\"\"\n",
    "    RICE_DATA = pd.read_excel(\"RICE_data.xlsx\")\n",
    "    RICE_PARAMETER = pd.read_excel(\"RICE_parameter.xlsx\")\n",
    "    RICE_input = pd.read_excel(\"input_data_RICE.xlsx\")\n",
    "    \n",
    "    RICE_income_shares = pd.read_excel(\"RICE_income_shares.xlsx\")\n",
    "    RICE_GDP_SSP = pd.read_excel(\"Y_Gross_ssp.xlsx\")\n",
    "\n",
    "    RICE_income_shares = RICE_income_shares.iloc[:,1:6].to_numpy()\n",
    "\n",
    "    #import dataframes for SSP uncertainty analysis\n",
    "    POP_ssp = pd.read_excel(\"pop_ssp.xlsx\")\n",
    "    POP_ssp = POP_ssp.iloc[1:,:]        \n",
    "\n",
    "    regions_list = [\"US\", \"OECD-Europe\",\"Japan\",\"Russia\",\"Non-Russia Eurasia\",\"China\",\"India\",\"Middle East\",\"Africa\",\n",
    "        \"Latin America\",\"OHI\",\"Other non-OECD Asia\"]\n",
    "\n",
    "    \"\"\"\n",
    "    ############################# LEVERS ###############################\n",
    "    \"\"\"\n",
    "\n",
    "    #setting up model levers\n",
    "    #if model is EMA the emission control rate miu is sampled \n",
    "    #if specification is DICE optimal, the optimal control rate range for every region is taken from Nordhaus \n",
    "\n",
    "\n",
    "    ###################### GET CONTROLS FROM RICE OPTIMAL RUN #########################\n",
    "\n",
    "    #welfare_function = welfare_function\n",
    "\n",
    "    #get lever series for RICE optimal run\n",
    "    miu_opt_series = RICE_input.iloc[15:27,1:].to_numpy()\n",
    "    sr_opt_series = RICE_input.iloc[30:42,1:].to_numpy()\n",
    "\n",
    "\n",
    "    #Controls with random sampling\n",
    "    if model_specification == \"EMA\":\n",
    "\n",
    "        #create frame for savings rate to be sampled\n",
    "        S = np.zeros((12, steps))\n",
    "        miu = np.zeros((12,steps))\n",
    "\n",
    "        #set starting MIU for all runs\n",
    "        miu[:,0:2] = miu_opt_series[:,0:2]\n",
    "        S[:,0:2] = sr_opt_series[:,0:2]\n",
    "\n",
    "        miu_period = np.full((12, 1), miu_period)\n",
    "        sr = sr\n",
    "\n",
    "\n",
    "\n",
    "    #full RICE2010 replicating run\n",
    "    if model_specification == \"Validation_1\":\n",
    "\n",
    "        #set savings rate and control rate as optimized RICE 2010          \n",
    "        S =  sr_opt_series \n",
    "\n",
    "        #set emission control rate for the whole run according to RICE2010 opt.\n",
    "        miu = miu_opt_series\n",
    "        irstp = irstp\n",
    "\n",
    "\n",
    "    #EMA Deterministic\n",
    "    if model_specification == \"Validation_2\":\n",
    "\n",
    "        #create dataframes for control rate and savings rate\n",
    "        miu = np.zeros((12,steps))\n",
    "        S = np.zeros((12, steps))\n",
    "\n",
    "        #set savings rate and control rate as optimized RICE 2010 for the first two timesteps\n",
    "        miu[:,0:2] = miu_opt_series[:,0:2]\n",
    "        S[:,0:2] = sr_opt_series[:,0:2]\n",
    "\n",
    "        #set uncertainties that drive MIU\n",
    "        limmiu= 1\n",
    "        irstp = irstp\n",
    "        miu_period = [12,15,15,10,10,11,13,13,13,14,13,14]\n",
    "\n",
    "    #define other uncertainties same over all instances\n",
    "    irstp = irstp\n",
    "    limmiu = limmiu\n",
    "    fosslim = fosslim\n",
    "\n",
    "    \"\"\"\n",
    "    ######################## DEEP UNCERTAINTIES ########################\n",
    "    \"\"\"\n",
    "\n",
    "    # Equilibrium temperature impact [dC per doubling CO2]/\n",
    "    # CLimate sensitivity parameter (3.2 RICE OPT)\n",
    "    t2xco2 = samples_t2xco2[t2xco2_dist][t2xco2_index]\n",
    "\n",
    "    # Choice of the damage function (structural deep uncertainty)\n",
    "    fdamage = fdamage\n",
    "\n",
    "    \"\"\"\n",
    "    ######################## OTHER UNCERTAINTIES ########################\n",
    "    \"\"\"\n",
    "    #define growth factor uncertainties for sampling\n",
    "    scenario_pop_gdp =scenario_pop_gdp\n",
    "    scenario_sigma = scenario_sigma\n",
    "    scenario_cback = scenario_cback\n",
    "\n",
    "    \"\"\"\n",
    "    ####################### Carbon cycle PARAMETERS #######################\n",
    "    \"\"\"            \n",
    "\n",
    "    #RICE2010 INPUTS\n",
    "    # Initial concentration in atmosphere 2000 [GtC]\n",
    "    mat0 = 787 \n",
    "    # Initial concentration in atmosphere 2010 [GtC]\n",
    "    mat1 = 829\n",
    "    # Initial concentration in upper strata [GtC]\n",
    "    mu0 = 1600.0 #1600 in excel\n",
    "    # Initial concentration in lower strata [GtC]\n",
    "    ml0 = 10010.0\n",
    "    # Equilibrium concentration in atmosphere [GtC]\n",
    "    mateq = 588.0 \n",
    "    # Equilibrium concentration in upper strata [GtC]\n",
    "    mueq = 1500.0 \n",
    "    # Equilibrium concentration in lower strata [GtC]\n",
    "    mleq = 10000.0\n",
    "\n",
    "    #parameters are scaled with 100, check with cllimate equations\n",
    "    b11 = 0.088                                   #88 in excel\n",
    "    b23 = 0.00500                                 #0.5 in excel\n",
    "    b12 = 1 -  b11                           \n",
    "    b21 =  b11 *  mateq /  mueq    \n",
    "    b22 = 1 -  b21 -  b23               #good in excel       \n",
    "    b32 =  b23 *  mueq /  mleq     #good in excel\n",
    "    b33 = 1 -  b32                           #good in excel       \n",
    "\n",
    "    # 2000 forcings of non-CO2 greenhouse gases (GHG) [Wm-2]\n",
    "    fex0 = -0.06\n",
    "    # 2100 forcings of non-CO2 GHG [Wm-2]\n",
    "    fex1 = 0.30\n",
    "    # Forcings of equilibrium CO2 doubling [Wm-2]\n",
    "    fco22x = 3.8\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    ###################### CLIMATE INITIAL VALUES ######################\n",
    "    \"\"\"\n",
    "    #RICE2010 INPUTS\n",
    "\n",
    "    # Equilibrium temperature impact [dC per doubling CO2]\n",
    "    # t2xco2 = t2xco2\n",
    "    # Initial lower stratum temperature change [dC from 1900]\n",
    "    tocean0 = 0.0068 \n",
    "    # Initial atmospheric temperature change [dC from 1900]\n",
    "    tatm0 = 0.83 \n",
    "\n",
    "\n",
    "    # 2013 version and earlier:\n",
    "    # Initial climate equation coefficient for upper level\n",
    "    # c10 = 0.098\n",
    "    # Regression slope coefficient (SoA~Equil TSC)\n",
    "    # c1beta = 0.01243\n",
    "    # Transient TSC Correction (\"Speed of Adjustment Parameter\")\n",
    "    # c1 = c10+c1beta*(t2xco2-2.9)\n",
    "\n",
    "    #DICE2013R\n",
    "    # Climate equation coefficient for upper level\n",
    "    #c1 = 0.098\n",
    "    # Transfer coefficient upper to lower stratum\n",
    "    #c3 = 0.088\n",
    "    # Transfer coefficient for lower level\n",
    "    #c4 = 0.025\n",
    "    # Climate model parameter\n",
    "    #lam =  fco22x /  t2xco2\n",
    "\n",
    "    #RICE2010\n",
    "    # Climate equation coefficient for upper level\n",
    "    c1 = 0.208\n",
    "    # Transfer coefficient upper to lower stratum\n",
    "    c3 = 0.310\n",
    "    # Transfer coefficient for lower level\n",
    "    c4 = 0.05\n",
    "    # Climate model parameter\n",
    "    lam =  fco22x /  t2xco2\n",
    "\n",
    "    \"\"\"\n",
    "    ######################### CARBON PARAMETERS ########################\n",
    "    \"\"\"\n",
    "\n",
    "    mat = np.zeros((steps,))\n",
    "    mu = np.zeros((steps,))\n",
    "    ml = np.zeros((steps,))\n",
    "    forcoth = np.zeros((steps,))\n",
    "    forc = np.zeros((steps,))\n",
    "\n",
    "    \"\"\"\n",
    "    ######################## CLIMATE PARAMETERS ########################\n",
    "    \"\"\"\n",
    "\n",
    "    # Increase temperature of atmosphere [dC from 1900]\n",
    "    temp_atm = np.zeros((steps,))\n",
    "    # Increase temperature of lower oceans [dC from 1900]\n",
    "    temp_ocean = np.zeros((steps,))\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    ######################## DAMAGE PARAMETERS ########################\n",
    "    \"\"\"\n",
    "\n",
    "    #damage parameters excluding SLR from base file \n",
    "    damage_parameters =  RICE_input.iloc[47:55,1:13]\n",
    "    damage_parameters = damage_parameters.transpose().to_numpy()\n",
    "\n",
    "    #damage parameters INCLUDING SLR FIT Dennig et \n",
    "    damage_parameters_slr_fit =  RICE_input.iloc[61:73,1:3]\n",
    "    damage_parameters_slr_fit = damage_parameters_slr_fit.to_numpy()\n",
    "\n",
    "    #include SHAJEE stuff here\n",
    "    \"\"\"\n",
    "    ####################### Capital and Economic PARAMETERS #######################\n",
    "    \"\"\"\n",
    "    #population parameteers\n",
    "    region_pop_gr = RICE_input.iloc[0:12,1:].to_numpy()\n",
    "\n",
    "    #get population data for 2005\n",
    "    population2005 = RICE_DATA.iloc[19:31,0].to_numpy()\n",
    "    region_pop = np.zeros((12,steps))\n",
    "\n",
    "    #get data for factor productivity growth\n",
    "    tfpgr_region =  RICE_DATA.iloc[52:64,1:32].to_numpy()\n",
    "\n",
    "    #get initial values for various parameters\n",
    "    initails_par = RICE_PARAMETER.iloc[33:40,5:17].to_numpy()\n",
    "    initials_par = initails_par.transpose()\n",
    "\n",
    "    #setting up total factor productivity\n",
    "    tfp_2005 = initials_par[:,5]\n",
    "    tfp_region = np.zeros((12, steps))\n",
    "\n",
    "    #setting up capital parameters\n",
    "    k_2005 = initials_par[:,4]\n",
    "    k_region = np.zeros((12, steps))\n",
    "    dk = 0.1\n",
    "    gama = 0.3\n",
    "\n",
    "    #setting up Y Gross\n",
    "    Y_gross = np.zeros((12, steps))\n",
    "    ynet = np.zeros((12, steps))\n",
    "    damages = np.zeros((12, steps))\n",
    "    dam_frac = np.zeros((12, steps))\n",
    "\n",
    "    #extra dataframe for calculating exponent - waarschijnlijk overbodig\n",
    "    Sigma_gr_tussenstap = pd.DataFrame(data=np.zeros([12, 1]))\n",
    "    Sigma_gr_tussenstap[\"exp\"] = \"\"\n",
    "\n",
    "    #Dataframes for emissions, economy and utility\n",
    "    Eind = np.zeros((12, steps))\n",
    "    E = np.zeros((12, steps))\n",
    "    Etree = np.zeros((12, steps))\n",
    "    cumetree = np.zeros((12, steps))\n",
    "    CCA = np.zeros((12, steps))\n",
    "    CCA_tot = np.zeros((12, steps))\n",
    "    Abetement_cost = np.zeros((12, steps))\n",
    "    Abetement_cost_RATIO = np.zeros((12, steps))\n",
    "    Mabetement_cost = np.zeros((12, steps))\n",
    "    CPRICE =np.zeros((12, steps))\n",
    "\n",
    "    #economy parameters per region\n",
    "    Y = np.zeros((12, steps))\n",
    "    I = np.zeros((12, steps))\n",
    "    C = np.zeros((12, steps))\n",
    "    CPC = np.zeros((12, steps))\n",
    "\n",
    "    #output metrics\n",
    "    util_sdr = np.zeros((12, steps))\n",
    "    inst_util = np.zeros((12, steps))\n",
    "    per_util = np.zeros((12, steps))\n",
    "\n",
    "    cum_util = np.zeros((12, steps))\n",
    "    reg_cum_util = np.zeros((12, steps))\n",
    "    reg_util = np.zeros((12, steps))\n",
    "    util = np.zeros((12, steps))\n",
    "\n",
    "    per_util_ww =  np.zeros((12, steps))\n",
    "    cum_per_util = np.zeros((12, steps))\n",
    "    inst_util_ww = np.zeros((12, steps))\n",
    "\n",
    "    #alternative SWF output arrays\n",
    "    sufficitarian_treshold = np.zeros((steps))\n",
    "    inst_util_tres = np.zeros((steps))\n",
    "    inst_util_tres_ww = np.zeros((12,steps))\n",
    "\n",
    "    #Output-to-Emission\n",
    "    #Change in sigma: the cumulative improvement in energy efficiency)\n",
    "    sigma_growth_data = RICE_DATA.iloc[70:82,1:6].to_numpy()\n",
    "    Emissions_parameter = RICE_PARAMETER.iloc[65:70,5:17].to_numpy().transpose()\n",
    "\n",
    "    #set up dataframe for saving CO2 to output ratio\n",
    "    Sigma_gr = np.zeros((12, steps))\n",
    "\n",
    "    #CO2-equivalent-emissions growth to output ratio in 2005\n",
    "    Sigma_gr[:,0] = sigma_growth_data[:,0]\n",
    "\n",
    "    #Period at which have full participation\n",
    "    periodfullpart = periodfullpart \n",
    "\n",
    "    # Fraction of emissions under control based on the Paris Agreement\n",
    "    # US withdrawal would change the value to 0.7086 \n",
    "    # https://climateanalytics.org/briefings/ratification-tracker/ (0.8875)\n",
    "    partfract2005 = 1\n",
    "\n",
    "    #Fraction of emissions under control at full time\n",
    "    partfractfull = 1.0\n",
    "\n",
    "    # Decline rate of decarbonization (per period)\n",
    "    decl_sigma_gr = -0.001\n",
    "\n",
    "    # Carbon emissions from land 2010 [GtCO2 per year]\n",
    "    eland0 = 1.6\n",
    "    # Decline rate of land emissions (per period) CHECKED\n",
    "    ecl_land = 0.2\n",
    "\n",
    "    # Elasticity of marginal utility of consumption (1.45) # CHECKED\n",
    "    elasmu = 1.50\n",
    "\n",
    "    #Emission data\n",
    "    emission_factor = RICE_DATA.iloc[87:99,6].to_numpy()\n",
    "    Eland0 = 1.6 #(RICE2010 OPT)\n",
    "    #Sigma_gr_tussenstap\n",
    "\n",
    "    #get alpha data\n",
    "    Alpha_data = RICE_DATA.iloc[357:369,1:60].to_numpy()\n",
    "    additative_scaling_weights = RICE_DATA.iloc[167:179,14:17].to_numpy()\n",
    "    multiplutacive_scaling_weights = RICE_DATA.iloc[232:244,1:2].to_numpy() / 1000\n",
    "\n",
    "    #Cost of abatement\n",
    "    abatement_data = RICE_PARAMETER.iloc[56:60,5:17].to_numpy().transpose()\n",
    "\n",
    "    pbacktime = np.zeros((12, steps))\n",
    "    cost1 =  np.zeros((12, steps))\n",
    "\n",
    "    #CO2 to economy ratio\n",
    "    sigma_region =  np.zeros((12, steps))\n",
    "    sigma_region[:,0] = Emissions_parameter[:,2] \n",
    "\n",
    "    #cback per region\n",
    "    cback_region = abatement_data[:,0]\n",
    "\n",
    "    #constations for backstop costs\n",
    "    ratio_asymptotic = abatement_data[:,2]\n",
    "    decl_back_gr = abatement_data[:,3]\n",
    "    expcost2 = 2.8   #RICE 2010 OPT\n",
    "\n",
    "    #disaggregated consumption tallys\n",
    "    CPC_post_damage = {}\n",
    "    CPC_pre_damage = {}\n",
    "    pre_damage_total__region_consumption = np.zeros((12, steps))\n",
    "\n",
    "    #dictionaries for quintile outputs\n",
    "    quintile_inst_util = {}\n",
    "    quintile_inst_util_ww = {}\n",
    "    quintile_inst_util_concave = {}\n",
    "    quintile_per_util_ww = {}\n",
    "\n",
    "    #prioritarian outputs\n",
    "    inst_util_worst_off = np.zeros((12,steps))\n",
    "    inst_util_worst_off_condition = np.zeros((12,steps))\n",
    "    worst_off_income_class = np.zeros((steps))\n",
    "    worst_off_income_class_index = np.zeros((steps))\n",
    "    worst_off_climate_impact = np.zeros((steps))\n",
    "    worst_off_climate_impact_index = np.zeros((steps))\n",
    "    climate_impact_per_income_share = {}\n",
    "\n",
    "\n",
    "    #sufficitarian outputs\n",
    "    sufficitarian_treshold = np.zeros((12,steps))\n",
    "    inst_util_tres = np.zeros((12,steps))\n",
    "    inst_util_tres_ww = np.zeros((12,steps))\n",
    "    quintile_inst_util = {}\n",
    "    quintile_inst_util_ww = {}\n",
    "    population_under_treshold = np.zeros((12,steps))\n",
    "    utility_distance_treshold = np.zeros((12,steps))\n",
    "    regions_under_treshold_index = np.zeros((12,steps))\n",
    "    largest_distance_under_treshold = np.zeros((12,steps))\n",
    "\n",
    "    #egalitarian outputs\n",
    "    utility_intra_gini = np.zeros((steps))\n",
    "    regional_period_utility_sum = np.zeros((steps))\n",
    "    intertemporal_gini = np.zeros((steps))\n",
    "    climate_impact_per_dollar_consumption = np.zeros((12,steps))\n",
    "    climate_impact_per_dollar_gini = np.zeros((steps))\n",
    "\n",
    "    \"\"\"\n",
    "    ####################### LIMITS OF THE MODEL ########################\n",
    "    \"\"\"\n",
    "\n",
    "    # Output low (constraints of the model)\n",
    "    y_lo = 0.0\n",
    "    ygross_lo = 0.0\n",
    "    i_lo = 0.0\n",
    "    c_lo = 2.0\n",
    "    cpc_lo = 0\n",
    "    k_lo = 1.0\n",
    "    # miu_up[0] = 1.0\n",
    "\n",
    "    mat_lo = 10.0\n",
    "    mu_lo = 100.0\n",
    "    ml_lo = 1000.0\n",
    "    temp_ocean_up = 20.0\n",
    "    temp_ocean_lo = -1.0\n",
    "    temp_atm_lo = 0.0\n",
    "\n",
    "    #temp_atm_up = 20 or 12 for 2016 version\n",
    "    temp_atm_up = 40.0      \n",
    "\n",
    "    \"\"\"\n",
    "    ####################### INI CARBON and climate SUB-MODEL #######################\n",
    "    \"\"\"\n",
    "\n",
    "    # Carbon pools\n",
    "    mat[0] = mat0\n",
    "    mat[1] = mat1\n",
    "\n",
    "    if(mat[0] < mat_lo):\n",
    "        mat[0] = mat_lo\n",
    "\n",
    "    mu[0] = mu0\n",
    "    if(mu[0] < mu_lo):\n",
    "        mu[0] = mu_lo\n",
    "\n",
    "    ml[0] = ml0\n",
    "    if(ml[0] < ml_lo):\n",
    "        ml[0] = ml_lo\n",
    "\n",
    "    # Radiative forcing\n",
    "    forcoth[0] = fex0\n",
    "    forc[0] = fco22x*(np.log(((mat[0]+mat[1])/2)/596.40)/np.log(2.0)) + forcoth[0]\n",
    "\n",
    "    \"\"\"\n",
    "    ################# CLIMATE PARAMETER INTITIALISATION ################\n",
    "    \"\"\"\n",
    "    #checked with RICE2010\n",
    "\n",
    "    # Atmospheric temperature\n",
    "    temp_atm[0] = tatm0\n",
    "\n",
    "    if(temp_atm[0] < temp_atm_lo):\n",
    "        temp_atm[0] = temp_atm_lo\n",
    "    if(temp_atm[0] > temp_atm_up):\n",
    "        temp_atm[0] = temp_atm_up\n",
    "\n",
    "    # Oceanic temperature\n",
    "    temp_ocean[0] = 0.007\n",
    "\n",
    "    if(temp_ocean[0] < temp_ocean_lo):\n",
    "        temp_ocean[0] = temp_ocean_lo\n",
    "    if(temp_ocean[0] > temp_ocean_up):\n",
    "        temp_ocean[0] = temp_ocean_up\n",
    "\n",
    "    \"\"\"\n",
    "    ################# SLR PARAMETER INTITIALISATION ################\n",
    "    \"\"\"\n",
    "\n",
    "    #define inputs\n",
    "    SLRTHERM = np.zeros((31))\n",
    "    THERMEQUIL = np.zeros((31))\n",
    "\n",
    "    GSICREMAIN = np.zeros((31))\n",
    "    GSICCUM = np.zeros((31))\n",
    "    GSICMELTRATE = np.zeros((31))\n",
    "    GISREMAIN = np.zeros((31))\n",
    "    GISMELTRATE = np.zeros((31))\n",
    "    GISEXPONENT = np.zeros((31))\n",
    "    GISCUM = np.zeros((31))\n",
    "    AISREMAIN = np.zeros((31))\n",
    "    AISMELTRATE = np.zeros((31))\n",
    "    AISCUM = np.zeros((31))\n",
    "    TOTALSLR = np.zeros((31))\n",
    "\n",
    "    #inputs\n",
    "    therm0 = 0.092066694\n",
    "    thermadj = 0.024076141\n",
    "    thermeq = 0.5\n",
    "\n",
    "    gsictotal = 0.26\n",
    "    gsicmelt= 0.0008\n",
    "    gsicexp = 1\n",
    "    gsieq = -1\n",
    "\n",
    "    gis0 = 7.3\n",
    "    gismelt0 = 0.6\n",
    "    gismeltabove = 1.118600816\n",
    "    gismineq = 0\n",
    "    gisexp = 1\n",
    "\n",
    "    aismelt0 = 0.21\n",
    "    aismeltlow = -0.600407185\n",
    "    aismeltup = 2.225420209\n",
    "    aisratio = 1.3\n",
    "    aisinflection = 0\n",
    "    aisintercept = 0.770332789\n",
    "    aiswais = 5\n",
    "    aisother = 51.6\n",
    "\n",
    "    THERMEQUIL[0] = temp_atm[0] * thermeq\n",
    "    SLRTHERM[0] = therm0 + thermadj * (THERMEQUIL[0] - therm0)\n",
    "\n",
    "    GSICREMAIN[0] = gsictotal\n",
    "\n",
    "    GSICMELTRATE[0] = gsicmelt * 10 * (GSICREMAIN[0] / gsictotal)**(gsicexp) * (temp_atm[0] - gsieq )\n",
    "    GSICCUM[0] = GSICMELTRATE[0] \n",
    "    GISREMAIN[0] = gis0\n",
    "    GISMELTRATE[0] = gismelt0\n",
    "    GISCUM[0] = gismelt0 / 100\n",
    "    GISEXPONENT[0] = 1\n",
    "    AISREMAIN[0] = aiswais + aisother\n",
    "    AISMELTRATE[0] = 0.1225\n",
    "    AISCUM[0] = AISMELTRATE[0] / 100\n",
    "\n",
    "    TOTALSLR[0] = SLRTHERM[0] + GSICCUM[0] + GISCUM[0] + AISCUM[0]\n",
    "\n",
    "    slrmultiplier = 2\n",
    "    slrelasticity = 4\n",
    "\n",
    "    SLRDAMAGES = np.zeros((12,steps))\n",
    "    slrdamlinear = np.array([0,0.00452, 0.00053 ,0, 0.00011 , 0.01172 ,0, 0.00138 , 0.00351, 0, 0.00616,0])\n",
    "    slrdamquadratic = np.array([0.000255,0,0.000053,0.000042,0,0.000001,0.000255,0,0,0.000071,0,0.001239])\n",
    "\n",
    "    SLRDAMAGES[:,0] = 0\n",
    "\n",
    "    \"\"\"\n",
    "    ################# ECONOMIC PARAMETER INTITIALISATION ################\n",
    "    \"\"\"\n",
    "\n",
    "    #Insert population at 2005 for all regions\n",
    "    region_pop[:,0] = population2005\n",
    "\n",
    "    #total factor production at 2005\n",
    "    tfp_region[:,0] = tfp_2005\n",
    "\n",
    "    #initial capital in 2005\n",
    "    k_region[:,0] = k_2005\n",
    "\n",
    "    # Gama: Capital elasticity in production function\n",
    "    Y_gross[:,0] = (tfp_region[:,0]*((region_pop[:,0]/1000)**(1-gama)) * (k_region[:,0]**gama))\n",
    "\n",
    "    #original RICE parameters dam_frac with SLR\n",
    "    if fdamage == 0:\n",
    "        dam_frac[:,0] =  (damage_parameters[:,0]*temp_atm[0] \n",
    "                        + damage_parameters[:,1]*(temp_atm[0]**damage_parameters[:,2])) * 0.01\n",
    "\n",
    "    #Damage parameters RICE2010 fitted with extra SLR component\n",
    "    if fdamage == 1:\n",
    "        dam_frac[:,0] = 0.01 * (damage_parameters_slr_fit[:,0] * temp_atm[0] + \n",
    "                                          (damage_parameters_slr_fit[:,1] *\n",
    "                                           (temp_atm[0]**damage_parameters[:,2])))\n",
    "\n",
    "    #Net output damages\n",
    "    ynet[:,0] = Y_gross[:,0]/(1.0+dam_frac[:,0])\n",
    "\n",
    "    #Damages in 2005\n",
    "    damages[:,0] = Y_gross[:,0] - ynet[:,0]\n",
    "\n",
    "    #Cost of backstop\n",
    "    pbacktime[:,0] = cback_region\n",
    "\n",
    "    # Adjusted cost for backstop\n",
    "    cost1[:,0] = pbacktime[:,0]*sigma_region[:,0]/expcost2\n",
    "\n",
    "    #decline of backstop competitive year (RICE2010 OPT)\n",
    "    periodfullpart = 2250\n",
    "\n",
    "    #Emissions from land change use\n",
    "    Etree[:,0] = Emissions_parameter[:,3]\n",
    "    cumetree[:,0] = Emissions_parameter[:,3]\n",
    "\n",
    "    #industrial emissions 2005\n",
    "    Eind[:,0] =  sigma_region[:,0] * Y_gross[:,0] * (1 - miu[:,0])\n",
    "\n",
    "    #initialize initial emissions\n",
    "    E[:,0] = Eind[:,0] + Etree[:,0]\n",
    "    CCA[:,0] = Eind[:,0]\n",
    "    CCA_tot[:,0] = CCA[:,0] + cumetree[:,0]\n",
    "\n",
    "    #doesnt do much here\n",
    "    partfract = 1 \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    ####################### INIT NET ECONOMY SUB-MODEL ######################\n",
    "    \"\"\"                   \n",
    "\n",
    "    #Cost of climate change to economy\n",
    "    #Abettement cost ratio of output\n",
    "    Abetement_cost_RATIO[:,0] = cost1[:,0]*(miu[:,0] ** expcost2)\n",
    "\n",
    "    #Abettement cost total\n",
    "    Abetement_cost[:,0] = Y_gross[:,0] * Abetement_cost_RATIO[:,0]\n",
    "\n",
    "    #Marginal abetement cost\n",
    "    Mabetement_cost[:,0] = pbacktime[:,0] * miu[:,0]**(expcost2-1)\n",
    "\n",
    "    #Resulting carbon price\n",
    "    CPRICE[:,0] = pbacktime[:,0] * 1000 * (miu[:,0]**(expcost2-1))     \n",
    "\n",
    "    # Gross world product (net of abatement and damages)\n",
    "    Y[:,0] = ynet[:,0]-Abetement_cost[:,0]           \n",
    "\n",
    "    ##############  Investments & Savings  #########################\n",
    "\n",
    "    #investments per region given the savings rate \n",
    "    I[:,0] = S[:,0] * Y[:,0]\n",
    "\n",
    "    #consumption given the investments\n",
    "    C[:,0] = Y[:,0] - I[:,0]\n",
    "\n",
    "    #placeholder for different damagefactor per quintile\n",
    "    quintile_damage_factor = 1\n",
    "\n",
    "    #calculate pre damage consumption aggregated per region\n",
    "    pre_damage_total__region_consumption[:,0] = C[:,0] + damages[:,0]\n",
    "\n",
    "    #calculate damage share with damage factor per quintile\n",
    "    damage_share = RICE_income_shares.transpose() * quintile_damage_factor\n",
    "\n",
    "    #calculate disaggregated per capita consumption based on income shares BEFORE damages\n",
    "    CPC_pre_damage[2005] = ((pre_damage_total__region_consumption[:,0] * RICE_income_shares.transpose() )  / (region_pop[:,0] * (1 / 5))) * 1000\n",
    "\n",
    "    #calculate disaggregated per capita consumption based on income shares AFTER damages\n",
    "    CPC_post_damage[2005] = CPC_pre_damage[2005]  - (((damages[:,0] *  damage_share ) / (region_pop[:,0] * (1 / 5))) * 1000)\n",
    "\n",
    "    #consumption per capita\n",
    "    CPC[:,0] = (1000 * C[:,0]) / region_pop[:,0]\n",
    "\n",
    "    ######################################### Utility #########################################\n",
    "\n",
    "    #Initial rate of social time preference per year\n",
    "    util_sdr[:,0] = 1\n",
    "\n",
    "    #Instantaneous utility function equation \n",
    "    inst_util[:,0] = ((1 / (1 - elasmu)) * (CPC[:,0])**(1 - elasmu) + 1) * Alpha_data[:,0]           \n",
    "\n",
    "    #CEMU period utilitity         \n",
    "    per_util[:,0] = inst_util[:,0] * region_pop[:,0] * util_sdr[:,0]\n",
    "\n",
    "    #Cummulativie period utilty without WW\n",
    "    cum_per_util[:,0] = per_util[:,0] \n",
    "\n",
    "    #Instantaneous utility function with welfare weights\n",
    "    inst_util_ww[:,0] = inst_util[:,0] * Alpha_data[:,0]\n",
    "\n",
    "    #Period utility with welfare weights\n",
    "    per_util_ww[:,0] = inst_util_ww[:,0] * region_pop[:,0] * util_sdr[:,0]\n",
    "\n",
    "    #cummulative utility with ww\n",
    "    reg_cum_util[:,0] =  per_util[:,0] \n",
    "\n",
    "    #scale utility with weights derived from the excel\n",
    "    reg_util[:,0] = 10  * multiplutacive_scaling_weights[:,0] * reg_cum_util[:,0] + additative_scaling_weights[:,0] - additative_scaling_weights[:,2]  \n",
    "\n",
    "    #calculate worldwide utility \n",
    "    utility = reg_util.sum()            \n",
    "\n",
    "    \"\"\"\n",
    "    ########################################## RICE MODEL ###################################################    \n",
    "    \"\"\"    \n",
    "\n",
    "\n",
    "    #Follows equations of notes #TOTAL OF 30 STEPS UNTIL 2305\n",
    "    for t in range(1,31): \n",
    "\n",
    "        \"\"\"\n",
    "        ####################### GROSS ECONOMY SUB-MODEL ######################\n",
    "        \"\"\"\n",
    "\n",
    "        #use ssp population projections if not base with right SSP scenario (SSP1, SSP2 etc.)\n",
    "        if scenario_pop_gdp !=0:\n",
    "\n",
    "            #load population and gdp projections from SSP scenarios on first timestep\n",
    "            if t == 1:\n",
    "                for region in range(0,12):\n",
    "                    region_pop[region,:] = POP_ssp.iloc[:,scenario_pop_gdp + (region * 5)]\n",
    "\n",
    "                    Y_gross[region,:] = RICE_GDP_SSP.iloc[:,scenario_pop_gdp + (region * 5)] / 1000\n",
    "\n",
    "            Y_gross[:,t] = np.where(Y_gross[:,t]  > 0, Y_gross[:,t], 0)\n",
    "\n",
    "            k_region[:,t] = k_region[:,t-1]*((1-dk)**tstep) + tstep*I[:,t-1]\n",
    "\n",
    "            #calculate tfp based on gdp projections by SSP's\n",
    "            tfp_region[:,t] = Y_gross[:,t] / ((k_region[:,t]**gama)*(region_pop[:,t]/1000)**(1-gama))\n",
    "\n",
    "        #base tfp projections RICE2010\n",
    "        else:\n",
    "            #calculate population at time t\n",
    "            region_pop[:,t] = region_pop[:,t-1] *  2.71828 **(region_pop_gr[:,t]*10)\n",
    "\n",
    "            #TOTAL FACTOR PRODUCTIVITY level according to RICE base\n",
    "            tfp_region[:,t] = tfp_region[:,t-1] * 2.71828 **(tfpgr_region[:,t]*10)\n",
    "\n",
    "            #determine capital stock at time t\n",
    "            k_region[:,t] = k_region[:,t-1]*((1-dk)**tstep) + tstep*I[:,t-1]\n",
    "\n",
    "            #lower bound capital\n",
    "            k_region[:,t] = np.where(k_region[:,t]  > 1, k_region[:,t] ,1)\n",
    "\n",
    "            #determine Ygross at time t\n",
    "            Y_gross[:,t] = tfp_region[:,t] * ((region_pop[:,t]/1000)**(1-gama))*(k_region[:,t]**gama)   \n",
    "\n",
    "            #lower bound Y_Gross\n",
    "            Y_gross[:,t] = np.where(Y_gross[:,t]  > 0, Y_gross[:,t], 0)\n",
    "\n",
    "        #capital and ygross show minor deviations after t =1 because of influence Y net\n",
    "        #damage function is slidely different because of different damage functions\n",
    "        #this influences the gross economy cycle as well as emissions, damages and welfare\n",
    "\n",
    "        #calculate the sigma growth and the emission rate development          \n",
    "        if t == 1:\n",
    "            Sigma_gr[:,t] = (sigma_growth_data[:,4] + (sigma_growth_data[:,2] - sigma_growth_data[:,4] )) \n",
    "\n",
    "            sigma_region[:,t] = sigma_region[:,t-1] *  (2.71828 ** (Sigma_gr[:,t]*10)) * emission_factor\n",
    "\n",
    "        if t > 1 :\n",
    "            Sigma_gr[:,t] = (sigma_growth_data[:,4] + (Sigma_gr[:,t-1] - sigma_growth_data[:,4]  ) * (1-sigma_growth_data[:,3] )) \n",
    "\n",
    "            sigma_region[:,t] = sigma_region[:,t-1] *  (2.71828 ** ( Sigma_gr[:,t]*10)) \n",
    "\n",
    "\n",
    "        #print(\"CO2 economy ratio = \" + str(t))\n",
    "        #print(sigma_region.iloc[:,t])\n",
    "\n",
    "        if model_specification == \"EMA\":\n",
    "            # control rate is maximum after target period, otherwise linearly increase towards that point from t[0]\n",
    "            # Control rate limit\n",
    "            if t > 1:\n",
    "                    for index in range(0,12):            \n",
    "                        calculated_miu = miu[index,t-1] + (limmiu - miu[index,1]) / miu_period[index]\n",
    "                        miu[index, t]= min(calculated_miu, 1.00)\n",
    "\n",
    "        if model_specification == \"Validation_2\": \n",
    "            if t > 1:\n",
    "                for index in range(0,12):            \n",
    "                    calculated_miu = miu[index,t-1] + (limmiu - miu[index,1]) / miu_period[index]\n",
    "                    miu[index, t]= min(calculated_miu, 1.00)\n",
    "\n",
    "\n",
    "        #controlrate is werird output does not match --> this will cause CO2 emissions also not to match\n",
    "        #print(\"Control rate = \" + str(t))\n",
    "        #print(miu.iloc[:,t])\n",
    "\n",
    "        #Define function for EIND --> BIG STOP FROM t = 0 to t =1 something not right\n",
    "        Eind[:,t] = sigma_region[:,t] * Y_gross[:,t] * (1 - miu[:,t])\n",
    "\n",
    "        #yearly emissions from land change\n",
    "        Etree[:,t] = Etree[:,t-1]*(1-Emissions_parameter[:,4])\n",
    "\n",
    "        #print(\"emissions from change in land use: t = \" + str(t))\n",
    "        #print(Etree.iloc[:,t])\n",
    "\n",
    "        #yearly combined emissions\n",
    "        E[:,t] = Eind[:,t] + Etree[:,t]\n",
    "\n",
    "        #cummulative emissions from land change\n",
    "        cumetree[:,t] = cumetree[:,t-1] + Etree[:,t] * 10 \n",
    "\n",
    "        #cummulative emissions from industry\n",
    "        CCA[:,t] = CCA[:,t-1] + Eind[:,t] * 10\n",
    "\n",
    "        CCA[:,t] = np.where(CCA[:,t]  < fosslim, CCA[:,t] ,fosslim)\n",
    "\n",
    "        #total cummulative emissions\n",
    "        CCA_tot = CCA[:,t] + cumetree[:,t]\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        ####################### CARBON SUB MODEL #######################\n",
    "        \"\"\"\n",
    "\n",
    "        # Carbon concentration increase in atmosphere [GtC from 1750]\n",
    "\n",
    "        E_worldwilde_per_year = E.sum(axis=0)  #1    #2      #3\n",
    "\n",
    "        #parameters are scaled with 100, check with cllimate equations\n",
    "        #b11 = 0.012                                 #88 in excel\n",
    "        #b23 = 0.00500                                 #0.5 in excel\n",
    "        #b12 = 1 -  b11                           \n",
    "        #b21 =  b11 *  mateq /  mueq    \n",
    "        #b22 = 1 -  b21 -  b23               #good in excel       \n",
    "        #b32 =  b23 *  mueq /  mleq     #good in excel\n",
    "        #b33 = 1 -  b32                           #good in excel       \n",
    "\n",
    "        #calculate concentration in bioshpere and upper oceans\n",
    "        mu[t] = 12/100 * mat[t-1] + 94.796/100*mu[t-1] + 0.075/100 *ml[t-1]\n",
    "\n",
    "        #set lower constraint for shallow ocean concentration\n",
    "        if(mu[t] < mu_lo):\n",
    "            mu[t] = mu_lo\n",
    "\n",
    "        # Carbon concentration increase in lower oceans [GtC from 1750]\n",
    "        ml[t] = 99.925/100 *ml[t-1]+0.5/100 * mu[t-1]\n",
    "\n",
    "        #set lower constraint for shallow ocean concentration\n",
    "        if(ml[t] < ml_lo):\n",
    "            ml[t] = ml_lo\n",
    "\n",
    "        #calculate concentration in atmosphere for t + 1 (because of averaging in forcing formula\n",
    "        if t < 30:\n",
    "            mat[t+1] = 88/100 * mat[t] + 4.704/100 * mu[t] + E_worldwilde_per_year[t]*10\n",
    "\n",
    "        #set lower constraint for atmospheric concentration\n",
    "        if(mat[t] < mat_lo):\n",
    "            mat[t] = mat_lo\n",
    "\n",
    "        # Radiative forcing\n",
    "\n",
    "        #Exogenous forcings from other GHG\n",
    "        #rises linearly from 2010 to 2100 from -0.060 to 0.3 then becomes stable in RICE -  UPDATE FOR DICE2016R\n",
    "\n",
    "        exo_forcing_2000 = -0.060\n",
    "        exo_forcing_2100 = 0.3000\n",
    "\n",
    "        if (t < 11):\n",
    "            forcoth[t] = fex0+0.1*(exo_forcing_2100 - exo_forcing_2000 )*(t)\n",
    "        else:\n",
    "            forcoth[t] = exo_forcing_2100\n",
    "\n",
    "\n",
    "        # Increase in radiative forcing [Wm-2 from 1900]\n",
    "        #forcing = constant * Log2( current concentration / concentration of forcing in 1900 at a doubling of CO2 (η)[◦C/2xCO2] ) + external forcing    \n",
    "        if t < 30:\n",
    "            forc[t] = fco22x*(np.log(((mat[t]+mat[t+1])/2)/(280*2.13)) / np.log(2.0)) + forcoth[t]\n",
    "        if t == 30:\n",
    "            forc[t] = fco22x*(np.log((mat[t])/(280*2.13)) / np.log(2.0)) + forcoth[t]\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        ####################### CLIMATE SUB-MODEL ######################\n",
    "        \"\"\"\n",
    "        #heating of oceans and atmospheric according to matrix equations\n",
    "        if t == 1:\n",
    "            temp_atm[t] = 0.980\n",
    "        if t > 1:\n",
    "            temp_atm[t] = (temp_atm[t-1]+c1\n",
    "                                * ((forc[t]-((fco22x/t2xco2)* temp_atm[t-1]))\n",
    "                                   - (c3*(temp_atm[t-1] - temp_ocean[t-1]))))\n",
    "\n",
    "        #setting up lower and upper bound for temperatures\n",
    "        if (temp_atm[t] < temp_atm_lo):\n",
    "            temp_atm[t] = temp_atm_lo\n",
    "\n",
    "        if (temp_atm[t] > temp_atm_up):\n",
    "            temp_atm[t] = temp_atm_up\n",
    "\n",
    "        temp_ocean[t] = (temp_ocean[t-1]+c4 * (temp_atm[t-1]-temp_ocean[t-1]))\n",
    "\n",
    "        #setting up lower and upper bound for temperatures\n",
    "        if (temp_ocean[t] < temp_ocean_lo):\n",
    "            temp_ocean[t] = temp_ocean_lo\n",
    "\n",
    "        if (temp_ocean[t] > temp_ocean_up):\n",
    "            temp_ocean[t] = temp_ocean_up\n",
    "\n",
    "        #thermal expansion\n",
    "        THERMEQUIL[t] = temp_atm[t] * thermeq\n",
    "\n",
    "        SLRTHERM[t] = SLRTHERM[t-1] + thermadj * (THERMEQUIL[t] - SLRTHERM[t-1])\n",
    "\n",
    "        #glacier ice cap\n",
    "        GSICREMAIN[t] = gsictotal - GSICCUM[t-1]\n",
    "\n",
    "        GSICMELTRATE[t] = gsicmelt * 10 * (GSICREMAIN[t] / gsictotal)**(gsicexp) * temp_atm[t]\n",
    "\n",
    "        GSICCUM[t] = GSICCUM[t-1] + GSICMELTRATE[t]    \n",
    "\n",
    "        #greenland\n",
    "        GISREMAIN[t] = GISREMAIN[t-1] - (GISMELTRATE[t-1] / 100)\n",
    "\n",
    "        if t > 1:\n",
    "            GISMELTRATE[t] = (gismeltabove * (temp_atm[t] - gismineq) + gismelt0) * GISEXPONENT[t-1]\n",
    "        else:\n",
    "            GISMELTRATE[1] = 0.60\n",
    "\n",
    "        GISCUM[t] = GISCUM[t-1] + GISMELTRATE[t] / 100\n",
    "\n",
    "        if t > 1:\n",
    "            GISEXPONENT[t] = 1 - (GISCUM[t] / gis0)**gisexp\n",
    "        else:\n",
    "            GISEXPONENT[t] = 1\n",
    "\n",
    "        #antartica ice cap\n",
    "        if t <=11:\n",
    "            if temp_atm[t]< 3:\n",
    "                AISMELTRATE[t] = aismeltlow * temp_atm[t] * aisratio + aisintercept\n",
    "            else:\n",
    "                AISMELTRATE[t] = aisinflection * aismeltlow + aismeltup * (temp_atm[t] - 3.) + aisintercept\n",
    "        else:\n",
    "            if temp_atm[t] < 3:\n",
    "                AISMELTRATE[t] = aismeltlow * temp_atm[t] * aisratio + aismelt0\n",
    "            else:\n",
    "                AISMELTRATE[t] = aisinflection * aismeltlow + aismeltup * (temp_atm[t] - 3) + aismelt0\n",
    "\n",
    "        AISCUM[t] = AISCUM[t-1] + AISMELTRATE[t] / 100\n",
    "\n",
    "        AISREMAIN[t] = AISREMAIN[0] - AISCUM[t]\n",
    "\n",
    "        TOTALSLR[t] = SLRTHERM[t] + GSICCUM[t] + GISCUM[t] + AISCUM[t]\n",
    "\n",
    "        SLRDAMAGES[:,t] =  100 * slrmultiplier * (TOTALSLR[t-1] * slrdamlinear + (TOTALSLR[t-1]**2) * slrdamquadratic) * (Y_gross[:,t-1] / Y_gross[:,0])**(1/slrelasticity)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        ####################### NET ECONOMY SUB-MODEL ######################\n",
    "        \"\"\"\n",
    "\n",
    "        #original RICE parameters dam_frac\n",
    "        if fdamage == 0:\n",
    "            dam_frac[:,t] =  (damage_parameters[:,0]*temp_atm[t] + damage_parameters[:,1]*(temp_atm[t]**damage_parameters[:,2])) * 0.01\n",
    "\n",
    "            #Determine total damages\n",
    "            damages[:,t] = Y_gross[:,t]*(dam_frac[:,t] + (SLRDAMAGES[:,t] / 100))\n",
    "\n",
    "        #Damage parameters RICE2010 fitted with extra SLR component\n",
    "        if fdamage == 1:\n",
    "            dam_frac[:,t] = (damage_parameters_slr_fit[:,0]*temp_atm[t] \n",
    "                                       + damage_parameters_slr_fit[:,1]*\n",
    "                                       (temp_atm[t]**damage_parameters[:,2])) * 0.01\n",
    "\n",
    "            #determine total damages\n",
    "            damages[:,t] = Y_gross[:,t]*dam_frac[:,t]\n",
    "\n",
    "        #determine net output damages with damfrac function chosen in previous step\n",
    "        ynet[:,t] = Y_gross[:,t] - damages[:,t]\n",
    "\n",
    "        #print(\"Y net at time t = \" + str(t))\n",
    "        #print(ynet.iloc[:,t])\n",
    "\n",
    "        # Backstop price/cback: cost of backstop                \n",
    "        pbacktime[:,t] = 0.10 * cback_region + (pbacktime[:,t-1]- 0.1 * cback_region) * (1-decl_back_gr)\n",
    "\n",
    "        #print(pbacktime.iloc[:,t])\n",
    "\n",
    "        # Adjusted cost for backstop\n",
    "        cost1[:,t] = ((pbacktime[:,t]*sigma_region[:,t])/expcost2)\n",
    "\n",
    "        #print(\"adjusted cost of backstop at t =  \" + str(t))\n",
    "        #print(cost1.iloc[:,t])\n",
    "\n",
    "        #Abettement cost ratio of output\n",
    "        Abetement_cost_RATIO[:,t] = cost1[:,t]*(miu[:,t]** expcost2)\n",
    "\n",
    "        Abetement_cost[:,t] = Y_gross[:,t] * Abetement_cost_RATIO[:,t]\n",
    "\n",
    "        #print(\"abatement  cost in trillion $ at time t = \" + str(t))\n",
    "        #print(Abetement_cost.iloc[:,t])\n",
    "\n",
    "        #Marginal abetement cost\n",
    "        Mabetement_cost[:,t] = pbacktime[:,t] * (miu[:,t]**(expcost2-1))\n",
    "\n",
    "        #Resulting carbon price\n",
    "        #goes wrong here miu not right --> different from excel ?\n",
    "        CPRICE[:,t] = pbacktime[:,t] * 1000 * (miu[:,t]**(expcost2-1))             \n",
    "\n",
    "        #print(\"carbon price  at t =  \" + str(t))\n",
    "        #print(CPRICE.iloc[:,t])\n",
    "\n",
    "        # Gross world product (net of abatement and damages)\n",
    "        Y[:,t] = ynet[:,t] - abs(Abetement_cost[:,t])\n",
    "\n",
    "        Y[:,t] = np.where(Y[:,t] > 0, Y[:,t], 0)\n",
    "\n",
    "        ##############  Investments & Savings  #########################\n",
    "        if model_specification != 'Validation_1':\n",
    "            # Optimal long-run savings rate used for transversality --> SEE THESIS SHAJEE\n",
    "            optlrsav = ((dk + 0.004) / (dk+ 0.004 * elasmu + irstp) * gama)\n",
    "\n",
    "            if model_specification == 'Validation_2':\n",
    "                    if t > 12:\n",
    "                        S[:,t] = optlrsav\n",
    "                    else: \n",
    "                        if t > 1: \n",
    "                                S[:,t] = (optlrsav - S[:,1]) * t / 12 + S[:,1]\n",
    "\n",
    "            if model_specification == 'EMA':\n",
    "                    if t > 25:\n",
    "                        S[:,t] = optlrsav\n",
    "                    else: \n",
    "                        if t > 1: \n",
    "                                S[:,t] = (sr - S[:,1]) * t / 12 + S[:,1]\n",
    "                        if t > 12:\n",
    "                            S[:,t] = sr\n",
    "\n",
    "        #investments per region given the savings rate -\n",
    "\n",
    "        I[:,t] = S[:,t]* Y[:,t]\n",
    "\n",
    "        #check lower bound investments\n",
    "        I[:,t] = np.where(I[:,t] > 0, I[:,t], 0)\n",
    "\n",
    "        #set up constraints\n",
    "        c_lo = 2\n",
    "        CPC_lo = 0.01\n",
    "\n",
    "        #consumption given the investments\n",
    "        C[:,t] = Y[:,t] - I[:,t]\n",
    "\n",
    "        #check for lower bound on C\n",
    "        C[:,t] = np.where(C[:,t]  > c_lo, C[:,t] , c_lo)\n",
    "\n",
    "        #keep track of year for storing in dict\n",
    "        year = 2005 + 10 * t\n",
    "\n",
    "        #calculate pre damage consumption aggregated per region\n",
    "        pre_damage_total__region_consumption[:,t] = C[:,t] + damages[:,t]\n",
    "\n",
    "        #damage spread equally across every person\n",
    "        #damage_share = (model.RICE_income_shares**0 ) * 0.2\n",
    "\n",
    "        #damage share according to Denig et al 2015\n",
    "        damage_share = RICE_income_shares**-1\n",
    "        sum_damage = np.sum(damage_share,axis=1)\n",
    "\n",
    "        for i in range(0,12):\n",
    "            damage_share[i,:] = damage_share [i,:]/sum_damage[i]           \n",
    "\n",
    "        #calculate disaggregated per capita consumption based on income shares BEFORE damages\n",
    "        CPC_pre_damage[year] = ((pre_damage_total__region_consumption[:,t] * RICE_income_shares.transpose() )  / (region_pop[:,t] * (1 / 5))) * 1000\n",
    "\n",
    "        #calculate disaggregated per capita consumption based on income shares AFTER damages\n",
    "        CPC_post_damage[year] = CPC_pre_damage[year]  - (((damages[:,t] *  damage_share.transpose() ) / (region_pop[:,t] * (1 / 5))) * 1000)\n",
    "\n",
    "        #calculate damage per quintile equiv\n",
    "        climate_impact_per_income_share[year] = damages[:,t] *  damage_share.transpose()\n",
    "\n",
    "        #average consumption per capita per region\n",
    "        CPC[:,t] = (1000 * C[:,t]) / region_pop[:,t]\n",
    "\n",
    "        CPC[:,t] = np.where(CPC[:,t]  > CPC_lo, CPC[:,t] , CPC_lo)\n",
    "\n",
    "        ################################## Utility ##################################\n",
    "\n",
    "        #set up df to check swfs\n",
    "\n",
    "        if welfare_function == \"utilitarian\":\n",
    "            print(\"utilitarian SWF is used\")\n",
    "\n",
    "            # irstp: Initial rate of social time preference per year\n",
    "            util_sdr[:,t] = 1/((1+irstp)**(tstep*(t)))\n",
    "\n",
    "            #instantaneous welfare without ww\n",
    "            inst_util[:,t] = ((1 / (1 - elasmu)) * (CPC[:,t])**(1 - elasmu) + 1) \n",
    "\n",
    "            #period utility \n",
    "            per_util[:,t] = inst_util[:,t] * region_pop[:,t] * util_sdr[:,t]\n",
    "\n",
    "            #cummulativie period utilty without WW\n",
    "            cum_per_util[:,0] = cum_per_util[:,t-1] + per_util[:,t] \n",
    "\n",
    "            #Instantaneous utility function with welfare weights\n",
    "            inst_util_ww[:,t] = inst_util[:,t] * Alpha_data[:,t]\n",
    "\n",
    "            #period utility with welfare weights\n",
    "            per_util_ww[:,t] = inst_util_ww[:,t] * region_pop[:,t] * util_sdr[:,t]\n",
    "            #cummulative utility with ww\n",
    "            reg_cum_util[:,t] =  reg_cum_util[:,t-1] + per_util_ww[:,t]\n",
    "\n",
    "            #scale utility with weights derived from the excel\n",
    "            if t == 30:\n",
    "                reg_util[:,t] = 10  * multiplutacive_scaling_weights[:,0] * reg_cum_util[:,t] + additative_scaling_weights[:,0] - additative_scaling_weights[:,2]  \n",
    "\n",
    "                print(\"total scaled cummulative regional utility\")\n",
    "                print(reg_util[:,t])\n",
    "\n",
    "            #calculate worldwide utility \n",
    "            utility = reg_util.sum()\n",
    "\n",
    "\n",
    "\n",
    "        if welfare_function == \"prioritarian\":\n",
    "            print(\"prioritarian SWF is used\")\n",
    "\n",
    "            #specify growth factor for conditional discounting\n",
    "            growth_factor = growth_factor_prio\n",
    "            prioritarian_discounting = prioritarian_discounting\n",
    "\n",
    "\n",
    "            # irstp: Initial rate of social time preference per year\n",
    "            util_sdr[:,t] = 1/((1+irstp)**(tstep*(t)))\n",
    "\n",
    "            #instantaneous welfare without ww\n",
    "            inst_util[:,t] = ((1 / (1 - elasmu)) * (CPC[:,t])**(1 - elasmu) + 1) \n",
    "\n",
    "            #period utility withouw ww\n",
    "            per_util[:,t] = inst_util[:,t] * region_pop[:,t] * util_sdr[:,t]\n",
    "\n",
    "            #cummulativie period utilty without WW\n",
    "            cum_per_util[:,0] = cum_per_util[:,t-1] + per_util[:,t] \n",
    "\n",
    "            #Instantaneous utility function with welfare weights\n",
    "            inst_util_ww[:,t] = inst_util[:,t] * Alpha_data[:,t]\n",
    "\n",
    "            #check for discounting prioritarian\n",
    "\n",
    "            #no discounting used\n",
    "            if prioritarian_discounting == \"no discounting\":\n",
    "                per_util_ww[:,t] = inst_util_ww[:,t] * region_pop[:,t]\n",
    "\n",
    "            #only execute discounting when the lowest income groups experience consumption level growth \n",
    "            if prioritarian_discounting == \"conditional discounting\":\n",
    "                #utility worst-off\n",
    "                inst_util_worst_off[:,t] = ((1 / (1 - elasmu)) * (CPC_post_damage[year][0])**(1 - elasmu) + 1)     \n",
    "\n",
    "                inst_util_worst_off_condition[:,t] = ((1 / (1 - elasmu)) * (CPC_post_damage[year-10][0] * growth_factor)**(1 - elasmu) + 1)     \n",
    "\n",
    "                #apply discounting when all regions experience enough growth\n",
    "\n",
    "                for region in range(0,12):\n",
    "                    if inst_util_worst_off[region,t] >= inst_util_worst_off_condition[region,t]:\n",
    "                        per_util_ww[region,t] = inst_util_ww[region,t] * region_pop[region,t] * util_sdr[region,t]\n",
    "\n",
    "                    #no discounting when lowest income groups do not experience enough growth\n",
    "                    else:\n",
    "                        per_util_ww[region,t] = inst_util_ww[region,t]* region_pop[region,t]                        \n",
    "\n",
    "            #objective for the worst-off region in terms of consumption per capita\n",
    "            worst_off_income_class[t] = CPC_post_damage[year][0].min()\n",
    "\n",
    "            array_worst_off_income = CPC_post_damage[year][0]\n",
    "            worst_off_income_class_index[t] = np.argmin(array_worst_off_income)\n",
    "\n",
    "            #objective for the worst-off region in terms of climate impact\n",
    "            worst_off_climate_impact[t] = climate_impact_per_income_share[year][0].min()\n",
    "\n",
    "            array_worst_off_share = climate_impact_per_income_share[year][0]\n",
    "            worst_off_climate_impact_index[t] = np.argmin(array_worst_off_share)\n",
    "\n",
    "            #cummulative utility with ww\n",
    "            reg_cum_util[:,t] =  reg_cum_util[:,t-1] + per_util_ww[:,t]\n",
    "\n",
    "            #scale utility with weights derived from the excel\n",
    "            if t == 30:\n",
    "                reg_util[:,t] = 10  * multiplutacive_scaling_weights[:,0] * reg_cum_util[:,t] + additative_scaling_weights[:,0] - additative_scaling_weights[:,2]  \n",
    "\n",
    "                print(\"total scaled cummulative regional utility\")\n",
    "                print(reg_util[:,t])\n",
    "\n",
    "            #calculate worldwide utility \n",
    "            utility = reg_util.sum()\n",
    "\n",
    "\n",
    "\n",
    "        if welfare_function == \"sufficitarian\":\n",
    "            print(\"sufficitarian SWF is used\")\n",
    "\n",
    "            #sufficitarian controls\n",
    "            sufficitarian_discounting = sufficitarian_discounting\n",
    "            growth_factor = growth_factor_suf\n",
    "            ini_suf_treshold = ini_suf_treshold,  #specified in consumption per capita thousand/year \n",
    "\n",
    "            #growth by technology frontier\n",
    "            growth_frontier = (np.max(CPC[:,t]) - np.max(CPC[:,t-1]))/np.max(CPC[:,t-1])\n",
    "\n",
    "            sufficitarian_treshold[t] = ini_suf_treshold * growth_frontier\n",
    "\n",
    "            #irstp: Initial rate of social time preference per year\n",
    "            util_sdr[:,t] = 1/((1+irstp)**(tstep*(t)))\n",
    "\n",
    "            #instantaneous welfare without ww\n",
    "            inst_util[:,t] = ((1 / (1 - elasmu)) * (CPC[:,t])**(1 - elasmu) + 1) \n",
    "\n",
    "            #calculate instantaneous welfare equivalent of minimum capita per head \n",
    "            inst_util_tres[t] = ((1 / (1 - elasmu)) * (sufficitarian_treshold[t])**(1 - elasmu) + 1) \n",
    "\n",
    "            #period utility \n",
    "            per_util[:,t] = inst_util[:,t] * region_pop[:,t] * util_sdr[:,t]\n",
    "\n",
    "            #cummulativie period utilty without WW\n",
    "            cum_per_util[:,0] = cum_per_util[:,t-1] + per_util[:,t] \n",
    "\n",
    "            #Instantaneous utility function with welfare weights\n",
    "            inst_util_ww[:,t] = inst_util[:,t] * Alpha_data[:,t]\n",
    "\n",
    "            #calculate instantaneous welfare equivalent of minimum capita per head with PPP\n",
    "            inst_util_tres_ww[:,t] = inst_util_tres[t] * Alpha_data[:,t]\n",
    "\n",
    "            print(\"sufficitarian treshold in utility\")\n",
    "            print(inst_util_tres_ww[:,t])\n",
    "\n",
    "            #calculate utility equivalent for every income quintile and scale with welfare weights for comparison\n",
    "            quintile_inst_util[year] = ((1 / (1 - elasmu)) * (CPC_post_damage[year])**(1 - elasmu) + 1)\n",
    "            quintile_inst_util_ww[year] = quintile_inst_util[year] * Alpha_data[:,t]       \n",
    "\n",
    "            utility_per_income_share = quintile_inst_util_ww[year]\n",
    "\n",
    "            index = 0\n",
    "\n",
    "            for quintile in range(0,5):\n",
    "                for region in range(0,12):\n",
    "                    if utility_per_income_share[quintile,region] < inst_util_tres_ww[region,t]:                            \n",
    "                        population_under_treshold[t] = population_under_treshold[t] + region_pop[region,t] * 1/5\n",
    "                        utility_distance_treshold[region,t] = inst_util_tres_ww[region,t] - utility_per_income_share[quintile,region]\n",
    "\n",
    "                        regions_under_treshold_index[index,t] = region\n",
    "\n",
    "                        index = index + 1\n",
    "\n",
    "            #objective: minimize distance under treshold           \n",
    "            largest_distance_under_treshold[t] = np.max(utility_distance_treshold[:,t])         \n",
    "\n",
    "            #sufficitarian discounting\n",
    "\n",
    "            #only discount when economy situations is as good as timestep before in every region\n",
    "            if sufficitarian_discounting == \"inheritance discounting\":\n",
    "                for region in range(0,12):\n",
    "                    if inst_util_ww[region,t] < inst_util_ww[region,t-1]:\n",
    "                        per_util_ww[:,t] = inst_util_ww[:,t] * region_pop[:,t]\n",
    "                        break\n",
    "                    else:\n",
    "                        per_util_ww[region,t] = inst_util_ww[region,t] * region_pop[region,t] * util_sdr[region,t]\n",
    "\n",
    "\n",
    "            #only discount when next generation experiences certain growth in every region\n",
    "            if sufficitarian_discounting == \"sustainable growth discounting\":\n",
    "                for region in range(0,12):\n",
    "                    if inst_util_ww[region,t] < inst_util_ww[region,t-1] * growth_factor:\n",
    "                        per_util_ww[:,t] = inst_util_ww[:,t] * region_pop[:,t]\n",
    "                        break\n",
    "                    else:\n",
    "                        per_util_ww[region,t] = inst_util_ww[region,t] * region_pop[region,t] * util_sdr[region,t]\n",
    "\n",
    "            #cummulative utility with ww\n",
    "            reg_cum_util[:,t] =  reg_cum_util[:,t-1] + per_util_ww[:,t]\n",
    "\n",
    "            #scale utility with weights derived from the excel\n",
    "            if t == 30:\n",
    "                reg_util[:,t] = 10  * multiplutacive_scaling_weights[:,0] * reg_cum_util[:,t] + additative_scaling_weights[:,0] - additative_scaling_weights[:,2]  \n",
    "\n",
    "                print(\"total scaled cummulative regional utility\")\n",
    "                print(reg_util[:,t])\n",
    "\n",
    "            #calculate worldwide utility \n",
    "            utility = reg_util.sum()\n",
    "\n",
    "\n",
    "        if welfare_function == \"egalitarian\":\n",
    "            print(\"egalitarian SWF is used\")\n",
    "\n",
    "            #controls for egalitarian principles\n",
    "            egalitarian_discounting = egalitarian_discounting\n",
    "            egalitarian_temporal = egalitarian_temporal\n",
    "\n",
    "            #calculate IRSTP\n",
    "            util_sdr[:,t] = 1/((1+irstp)**(tstep*(t)))\n",
    "\n",
    "            #instantaneous welfare without ww\n",
    "            inst_util[:,t] = ((1 / (1 - elasmu)) * (CPC[:,t])**(1 - elasmu) + 1) \n",
    "\n",
    "            #period utility without ww\n",
    "            per_util[:,t] = inst_util[:,t] * region_pop[:,t] * util_sdr[:,t]\n",
    "\n",
    "            #cummulativie period utilty without WW\n",
    "            cum_per_util[:,0] = cum_per_util[:,t-1] + per_util[:,t]\n",
    "\n",
    "            #Instantaneous utility function with welfare weights\n",
    "            inst_util_ww[:,t] = inst_util[:,t] * Alpha_data[:,t]\n",
    "\n",
    "            #apply no discounting\n",
    "            if egalitarian_discounting == \"no discounting\":\n",
    "                per_util_ww[:,t] = inst_util_ww[:,t] * region_pop[:,t]\n",
    "\n",
    "            else:\n",
    "                per_util_ww[:,t] = inst_util_ww[:,t] * region_pop[:,t] * util_sdr[:,t]\n",
    "\n",
    "            #only execute discounting when the lowest income groups experience consumption level growth \n",
    "            if egalitarian_temporal == \"temporal egalitarity\":\n",
    "                per_util_ww[:,t] = inst_util_ww[:,t] * region_pop[:,t]\n",
    "\n",
    "                regional_period_utility_sum[t] = per_util_ww[:,t].sum()\n",
    "\n",
    "                input_gini = regional_period_utility_sum\n",
    "\n",
    "                diffsum = 0\n",
    "                for i, xi in enumerate(input_gini[:-1], 1):\n",
    "                    diffsum += np.sum(np.abs(xi - input_gini[i:]))\n",
    "\n",
    "                    intertemporal_gini[t] = diffsum / ((len(input_gini)**2)* np.mean(input_gini))\n",
    "\n",
    "            #calculate gini as measure of current inequality in welfare\n",
    "            input_gini = inst_util_ww[:,t]\n",
    "\n",
    "            diffsum = 0\n",
    "            for i, xi in enumerate(input_gini[:-1], 1):\n",
    "                diffsum += np.sum(np.abs(xi - input_gini[i:]))\n",
    "\n",
    "                utility_intra_gini[t] = diffsum / ((len(input_gini)**2)* np.mean(input_gini))\n",
    "\n",
    "\n",
    "            #calculate gini as measure of current inequality in climate impact (per dollar consumption)  \n",
    "            climate_impact_per_dollar_consumption[:,t] = damages[:,t] / CPC[:,t]\n",
    "\n",
    "            input_gini = climate_impact_per_dollar_consumption[:,t]\n",
    "\n",
    "            diffsum = 0\n",
    "            for i, xi in enumerate(input_gini[:-1], 1):\n",
    "                diffsum += np.sum(np.abs(xi - input_gini[i:]))\n",
    "\n",
    "                climate_impact_per_dollar_gini[t] = diffsum / ((len(input_gini)**2)* np.mean(input_gini))\n",
    "\n",
    "\n",
    "            #cummulative utility with ww\n",
    "            reg_cum_util[:,t] =  reg_cum_util[:,t-1] + per_util_ww[:,t]\n",
    "\n",
    "            #scale utility with weights derived from the excel\n",
    "            if t == 30:\n",
    "                reg_util[:,t] = 10  * multiplutacive_scaling_weights[:,0] * reg_cum_util[:,t] + additative_scaling_weights[:,0] - additative_scaling_weights[:,2]  \n",
    "\n",
    "                print(\"total scaled cummulative regional utility\")\n",
    "                print(reg_util[:,t])\n",
    "\n",
    "            #calculate worldwide utility \n",
    "            utility = reg_util.sum()\n",
    "\n",
    "\n",
    "        print(\"####################################################################\")\n",
    "        print(\"######################    NEXT STEP        #########################\")\n",
    "        print(\"####################################################################\")\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    ####################################################################\n",
    "    ###################### OUTCOME OF INTEREST #########################\n",
    "    ####################################################################\n",
    "    \"\"\"   \n",
    "\n",
    "    data = {'Atmospheric Temperature 2005': temp_atm[0],\n",
    "                 'Damages 2005': damages[:,0],\n",
    "                 'Industrial Emission 2005': Eind[:,0],\n",
    "                 'Utility 2005': per_util_ww[:,0],\n",
    "                 'Total Output 2005': Y[:,0],\n",
    "\n",
    "                 'Atmospheric Temperature 2055': temp_atm[5],\n",
    "                 'Damages 2055': damages[:,5],\n",
    "                 'Industrial Emission 2055': Eind[:,5],\n",
    "                 'Utility 2055': per_util_ww[:,5],\n",
    "                 'Total Output 2055': Y[:,5],\n",
    "\n",
    "                 'Atmospheric Temperature 2105': temp_atm[10],\n",
    "                 'Damages 2105': damages[:,10],\n",
    "                 'Industrial Emission 2105': Eind[:,10],\n",
    "                 'Utility 2105': per_util_ww[:,10],\n",
    "                 'Total Output 2105': Y[:,10],\n",
    "\n",
    "                 'Atmospheric Temperature 2155': temp_atm[15],\n",
    "                 'Damages 2155': damages[:,15],\n",
    "                 'Industrial Emission 2155': Eind[:,15],\n",
    "                 'Utility 2155': per_util_ww[:,15],\n",
    "                 'Total Output 2155': Y[:,15],\n",
    "\n",
    "                 'Atmospheric Temperature 2205': temp_atm[20],\n",
    "                 'Damages 2205': damages[:,20],\n",
    "                 'Industrial Emission 2205': Eind[:,20], \n",
    "                 'Utility 2205': per_util_ww[:,20],\n",
    "                 'Total Output 2205': Y[:,20],\n",
    "\n",
    "                 'Atmospheric Temperature 2305': temp_atm[30],\n",
    "                 'Damages 2305': damages[:,30],\n",
    "                 'Industrial Emission 2305': Eind[:,30],\n",
    "                 'Utility 2305': per_util_ww[:,30],\n",
    "                 'Total Output 2305': Y[:,30]}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "total scaled cummulative regional utility\n",
      "[651.23533895 548.1850261  145.95142045  53.47685414  30.57082953\n",
      " 116.63774184  68.09445871 164.4246858   50.30241978 163.65199372\n",
      " 169.39380848  95.21135543]\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Atmospheric Temperature 2005': 0.83,\n",
       " 'Damages 2005': array([0.01206617, 0.01426768, 0.00430713, 0.0013448 , 0.000725  ,\n",
       "        0.00808613, 0.0116675 , 0.0117919 , 0.00543462, 0.00651989,\n",
       "        0.0041349 , 0.00692666]),\n",
       " 'Industrial Emission 2005': array([1.66141402, 1.14566253, 0.36984064, 0.43100237, 0.25652713,\n",
       "        1.59994445, 0.40499472, 0.58943424, 0.19130299, 0.41212692,\n",
       "        0.5415685 , 0.36381784]),\n",
       " 'Utility 2005': array([ 195.43798825,  280.73750323,   77.343665  ,   50.68086463,\n",
       "           3.09836394, -305.96894727, -655.39579939,   82.37076957,\n",
       "        -635.74243254,  111.581843  ,   76.60988202, -351.40822402]),\n",
       " 'Total Output 2005': array([12.38583403, 13.0167898 ,  3.86597665,  1.6966119 ,  0.80661005,\n",
       "         5.32514661,  2.42916401,  3.46831145,  1.29509551,  4.55195636,\n",
       "         3.83791485,  2.61226208]),\n",
       " 'Atmospheric Temperature 2055': 1.9301151060030917,\n",
       " 'Damages 2055': array([0.18954888, 0.30583766, 0.04389046, 0.01797063, 0.01562111,\n",
       "        0.52810471, 0.29909074, 0.26157384, 0.26727101, 0.1393648 ,\n",
       "        0.10813767, 0.21116891]),\n",
       " 'Industrial Emission 2055': array([1.29250197, 0.88567699, 0.23987399, 0.24027533, 0.16708945,\n",
       "        2.04579358, 1.04271736, 1.08433762, 0.50537154, 0.7198093 ,\n",
       "        0.4394027 , 1.16182656]),\n",
       " 'Utility 2055': array([ 60.19154523,  91.42472635,  15.03130016,  25.89876826,\n",
       "         39.68027946, 941.61837711, 590.64664746, 181.46275506,\n",
       "        391.23958493, 215.84991195,  26.65793636, 435.62291972]),\n",
       " 'Total Output 2055': array([35.42476912, 33.77727463,  6.84998659,  4.15554276,  3.13786645,\n",
       "        32.63818827, 19.85992428, 20.81724221, 15.22031428, 22.31199385,\n",
       "        10.64013976, 20.58945159]),\n",
       " 'Atmospheric Temperature 2105': 2.8273377961894646,\n",
       " 'Damages 2105': array([0.7317426 , 1.10943114, 0.14100847, 0.06154845, 0.07191079,\n",
       "        2.39337783, 1.40874692, 1.19306547, 1.81075907, 0.60891041,\n",
       "        0.37512005, 1.27004287]),\n",
       " 'Industrial Emission 2105': array([0.56591931, 0.56143597, 0.128461  , 0.02744491, 0.02178593,\n",
       "        0.50893239, 0.75576263, 0.7247725 , 0.45993111, 0.56796035,\n",
       "        0.20339712, 1.0860152 ]),\n",
       " 'Utility 2105': array([ 19.48291793,  28.45252821,   4.1494379 ,   8.70261084,\n",
       "         23.70519634, 462.88067826, 589.86627602, 104.26750909,\n",
       "        670.99432255, 114.18768927,   7.65324259, 483.98507534]),\n",
       " 'Total Output 2105': array([62.42166951, 54.68072757, 10.11411455,  6.53990884,  6.6405421 ,\n",
       "        63.2735923 , 52.06043938, 49.39182929, 49.87753138, 47.75369337,\n",
       "        16.39951113, 60.47843718]),\n",
       " 'Atmospheric Temperature 2155': 2.9416039791417066,\n",
       " 'Damages 2155': array([1.24329925, 2.28322847, 0.24752716, 0.11394151, 0.14682089,\n",
       "        6.42194219, 2.87518905, 2.17321907, 4.14807132, 1.12330863,\n",
       "        0.78211141, 2.9234039 ]),\n",
       " 'Industrial Emission 2155': array([0.        , 0.0534757 , 0.01162872, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]),\n",
       " 'Utility 2155': array([  7.4997888 ,  11.55479882,   1.67684981,   4.12224669,\n",
       "         13.75740585, 231.90692478, 371.04637179,  46.46257246,\n",
       "        417.27956968,  56.6857153 ,   2.98102755, 309.80845268]),\n",
       " 'Total Output 2155': array([ 95.11702934,  85.56283252,  15.77007569,  11.14789105,\n",
       "         12.39665807, 109.65289594,  97.5842375 ,  77.90429421,\n",
       "         89.54098369,  80.69006662,  25.10192959, 114.61686416]),\n",
       " 'Atmospheric Temperature 2205': 2.675785466090226,\n",
       " 'Damages 2205': array([ 1.4906849 ,  3.48102154,  0.30357643,  0.14102828,  0.19199505,\n",
       "        12.35045471,  3.95356689,  2.85960466,  6.52017621,  1.38013507,\n",
       "         1.22743208,  4.65095189]),\n",
       " 'Industrial Emission 2205': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'Utility 2205': array([  3.23476909,   5.03214295,   0.74177785,   2.02842905,\n",
       "          7.46211001, 106.99178659, 202.40432018,  21.00501625,\n",
       "        213.66883545,  27.75880202,   1.25948169, 166.22532451]),\n",
       " 'Total Output 2205': array([131.56799214, 119.92701063,  22.08844966,  16.56655756,\n",
       "         19.238898  , 163.24841653, 150.76451415, 107.82236112,\n",
       "        131.75016726, 116.84298809,  34.80536321, 179.113685  ]),\n",
       " 'Atmospheric Temperature 2305': 2.406612453159785,\n",
       " 'Damages 2305': array([ 2.22803164,  7.22100734,  0.46891459,  0.20568628,  0.30690238,\n",
       "        32.28167365,  7.17110828,  5.12094242, 15.12134686,  2.16765016,\n",
       "         2.60321204, 11.13940446]),\n",
       " 'Industrial Emission 2305': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'Utility 2305': array([ 0.72559192,  1.11942088,  0.17617456,  0.52678667,  2.1855625 ,\n",
       "        20.4993129 , 59.22880135,  5.2344866 , 56.64089114,  7.58882519,\n",
       "         0.26438164, 39.76103315]),\n",
       " 'Total Output 2305': array([216.03578977, 203.72256166,  37.54606981,  29.15288635,\n",
       "         36.43691921, 292.63516164, 296.22268553, 189.43082353,\n",
       "        253.4654013 , 214.75738175,  58.02025109, 352.77385681])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    " %load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n",
      "utilitarian SWF is used\n",
      "total scaled cummulative regional utility\n",
      "[-524.60009079 -349.00433129  -58.75986395  -22.26601196  -11.28678556\n",
      " -272.7518647   -98.17375958 -124.7622238   -55.2851214  -185.71590757\n",
      " -127.66205548 -117.56229716]\n",
      "####################################################################\n",
      "######################    NEXT STEP        #########################\n",
      "####################################################################\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u03b7' in position 77810: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-e7cbb41ef4cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lprun'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-T output -f run run(50)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2325\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2326\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2327\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2328\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-148>\u001b[0m in \u001b[0;36mlprun\u001b[1;34m(self, parameter_s)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\line_profiler.py\u001b[0m in \u001b[0;36mlprun\u001b[1;34m(self, parameter_s)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtext_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[0mpfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[0mpfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m             \u001b[0mpfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             print('\\n*** Profile printout saved to text file %r. %s' % (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\u03b7' in position 77810: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "%lprun -T output -f run run(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(open('output', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
