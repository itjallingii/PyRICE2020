{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from ema_workbench import save_results, load_results\n",
    "from ema_workbench.analysis import parcoords\n",
    "from ema_workbench.analysis import clusterer, plotting, Density\n",
    "\n",
    "#%matplotlib inlin\n",
    "clr_palette = ([sns.color_palette(\"YlGn\", 15)[10],sns.cubehelix_palette(8)[6]])\n",
    "\n",
    "pydice_folder = \"C:/Users/ivart/OneDrive/Bureaublad/Afstuderen/WRR/PyRICE Ivar Tjallingii/PyRICE2020/6_Uncertainty Analysis/server/model_server\"\n",
    "print(pydice_folder)\n",
    "sys.path.append(pydice_folder)\n",
    "\n",
    "from ema_workbench import (perform_experiments, Model, Policy, Scenario, ReplicatorModel, RealParameter, IntegerParameter, ScalarOutcome, ArrayOutcome, \n",
    "                           Constant, ema_logging, SequentialEvaluator, MultiprocessingEvaluator, IpyparallelEvaluator)\n",
    "\n",
    "from PyRICE_V8_long_term_uncertainty import PyRICE\n",
    "\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_outcomes_uncertainty_v2 import get_all_model_outcomes_uncertainty_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints_to_save = np.arange(2005,2305+20,20)\n",
    "objectives_list_name = ['Intertemporal utility GINI','Intertemporal impact GINI','Total Aggregated Utility','Regions below treshold']\n",
    "\n",
    "objectives_list_timeseries_name = ['Damages ','Utility ',\n",
    "            'Lowest income per capita ','Highest climate impact per capita ',\n",
    "            'Distance to treshold ','Population under treshold ',\n",
    "            'Intratemporal utility GINI ','Intratemporal impact GINI ',\n",
    "            'Atmospheric Temperature ', 'Industrial Emission ', 'Total Output ']\n",
    "\n",
    "supplementary_list_timeseries_name = ['CPC ','Population ']\n",
    "supplementary_list_quintile_name = ['CPC pre damage ','CPC post damage ']\n",
    "\n",
    "outcomes_names_time_series = []\n",
    "for name in objectives_list_timeseries_name:\n",
    "    for year in timepoints_to_save:\n",
    "        name_year = name + str(year)\n",
    "        outcomes_names_time_series.append(name_year)\n",
    "\n",
    "outcomes_name_single = []\n",
    "outcomes_name_multiple= []\n",
    "for name in objectives_list_name:\n",
    "    if name == \"Regions below treshold\":\n",
    "        outcomes_name_multiple.append(name)\n",
    "    else:\n",
    "        outcomes_name_single.append(name)\n",
    "\n",
    "outcome_name_supplementary =[]\n",
    "for name in supplementary_list_timeseries_name:\n",
    "    for year in timepoints_to_save:\n",
    "        name_year = name + str(year)\n",
    "        outcome_name_supplementary.append(name_year)\n",
    "        \n",
    "outcome_name_supplementary_quintile=[]\n",
    "for name in supplementary_list_quintile_name:\n",
    "    for year in timepoints_to_save:\n",
    "        name_year = name + str(year)\n",
    "        outcome_name_supplementary_quintile.append(name_year)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RICE_POP_gr = pd.read_excel(\"RICE_2010_base_000.xlsm\", sheet_name=\"Pop_gr\")\n",
    "\n",
    "regions_list = [\"US\", \"OECD-Europe\",\"Japan\",\"Russia\",\"Non-Russia Eurasia\",\"China\",\"India\",\"Middle East\",\"Africa\",\n",
    "    \"Latin America\",\"OHI\",\"Other non-OECD Asia\"]\n",
    "\n",
    "\"\"\"\n",
    "####################### Population PARAMETERS and set up dataframe format #######################\n",
    "\"\"\"\n",
    "\n",
    "#get population growth rates for each region\n",
    "a=[]\n",
    "for i in range(31):  \n",
    "    if i == 0:\n",
    "        a.append(\"region\")\n",
    "    k = 2005 + 10 * i\n",
    "    k = str(k)\n",
    "    a.append(k)    \n",
    "\n",
    "region_pop_gr = RICE_POP_gr.iloc[10:22,3:35]\n",
    "region_pop_gr.columns =  a\n",
    "region_pop_gr = region_pop_gr.set_index('region') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_policies = pd.read_csv(\"example_policys_principles.csv\",index_col=0)\n",
    "\n",
    "principles_list =[\"utilitarian\",\"prioritarian\",\"egalitarian\",\"sufficitarian\",\"nordhaus\"]\n",
    "\n",
    "total_policy_list = []\n",
    "\n",
    "for principle in principles_list:\n",
    "    policies = all_policies[all_policies['principle']==principle]\n",
    "    policies = policies.dropna(axis='columns')\n",
    "    policies = policies.iloc[:,:-1]\n",
    "    policy_list_principle = []\n",
    "\n",
    "    #get list of policies as input for uncertainty sampling\n",
    "    for i in range(0,len(policies)):\n",
    "        policy_dict = policies.iloc[i].to_dict()\n",
    "        policy_list_principle.append(Policy(policies.index[i], **policy_dict)) \n",
    "    total_policy_list.append(policy_list_principle)\n",
    "total_policy_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_result import load_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_nordhaus = load_result('results_uncertainty_analsysis_long_term_local_test_nordhaus_runs_25000.tar.gz')\n",
    "experiments_nordF, outcomes_nord = result_nordhaus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_util = load_result('results_uncertainty_analsysis_long_term_utilitarian_runs_25000.tar.gz')\n",
    "experiments_util, outcomes_util= result_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ega2 = load_result('results_uncertainty_analsysis_long_term_policies_second_halfegalitarian_runs_25000.tar.gz')\n",
    "experiments_ega2, outcomes_ega2 = result_ega2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ega = load_result('results_uncertainty_analsysis_long_term_policiesegalitarian_runs_25000.tar.gz')\n",
    "experiments_ega, outcomes_ega = result_ega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_suf2 = load_result('results_uncertainty_analsysis_long_term_policies_second_halfsufficitarian_runs_25000.tar.gz')\n",
    "experiments_suf2, outcomes_suf2 = results_suf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_suf = load_result('results_uncertainty_analsysis_long_term_policiessufficitarian_runs_25000.tar.gz')\n",
    "experiments_suf, outcomes_suf = results_suf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_prio2 = load_result('results_uncertainty_analsysis_long_term_policies_second_halfprioritarian_runs_25000.tar.gz')\n",
    "experiments_prio2, outcomes_prio2 = results_prio2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_prio = load_result('results_uncertainty_analsysis_long_term_policiesprioritarian_runs_25000.tar.gz')\n",
    "experiments_prio, outcomes_prio = results_prio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get per region outputs and save in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_total= pd.DataFrame()\n",
    "\n",
    "#experiments_nord, outcomes_nord = results_nordhaus\n",
    "experiments_ega2[\"principle\"] = \"Egalitarian\"\n",
    "experiments_suf2[\"principle\"] = \"Sufficitarian\"\n",
    "experiments_prio2[\"principle\"] = \"Prioritarian\"\n",
    "\n",
    "experiments_util[\"principle\"] = \"Utilitarian\"\n",
    "experiments_ega[\"principle\"] = \"Egalitarian\"\n",
    "experiments_prio[\"principle\"] = \"Prioritarian\"\n",
    "experiments_suf[\"principle\"] = \"Sufficitarian\"\n",
    "experiments_nordF[\"principle\"] = \"Nordhaus policy\"\n",
    "\n",
    "outcomes_names_main = outcomes_names_time_series+outcomes_name_single\n",
    "\n",
    "for keys in outcomes_names_main:\n",
    "    experiments_ega[keys] = outcomes_ega[keys]\n",
    "    experiments_util[keys] = outcomes_util[keys]\n",
    "    experiments_suf[keys] = outcomes_suf[keys]\n",
    "    experiments_prio[keys] = outcomes_prio[keys]\n",
    "    experiments_nordF[keys] = outcomes_nord[keys]\n",
    "    experiments_suf2[keys] = outcomes_suf2[keys]\n",
    "    experiments_ega2[keys] = outcomes_ega2[keys]\n",
    "    experiments_prio2[keys] = outcomes_prio2[keys]\n",
    "\n",
    "\n",
    "experiments_total = pd.concat([experiments_prio2,experiments_suf2,experiments_ega2,experiments_ega,experiments_suf,experiments_prio,experiments_util,\n",
    "                               experiments_nordF],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_total.to_csv(\"long_term_uncertainty_experiments_total_complete.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get per region outputs and save in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save CPC as csv\n",
    "pop_keys = outcome_name_supplementary[16:32]\n",
    "\n",
    "tuples = ()\n",
    "index = pd.MultiIndex.from_tuples(tuples,names=['principle', 'year'])\n",
    "POP_total = pd.DataFrame(columns= region_pop_gr.index,index = index)\n",
    "\n",
    "principles = ['egalitarian','sufficitarian','utilitarian','prioritarian']\n",
    "outcomes = [outcomes_ega,outcomes_suf,outcomes_util,outcomes_prio]\n",
    "\n",
    "index_year = 0\n",
    "principle_index =0 \n",
    "\n",
    "for outcome_principle in outcomes:\n",
    "    for year in pop_keys:\n",
    "        length = (len(outcome_principle[year]))\n",
    "        if principles[principle_index] ==\"utilitarian\":\n",
    "            tuples = [(principles[principle_index],2005+index_year),]*(125*10**3)\n",
    "        else:\n",
    "            tuples = [(principles[principle_index],2005+index_year),]*10**5\n",
    "        index_1 = pd.MultiIndex.from_tuples(tuples, names=['principle', 'year'])\n",
    "        year_df = pd.DataFrame(data =outcome_principle[year], columns= region_pop_gr.index,index=index_1)\n",
    "\n",
    "        index_year = index_year +20\n",
    "        POP_total = pd.concat([POP_total,year_df],axis=0)\n",
    "    principle_index = principle_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POP_total.to_csv(\"long_term_POP_per_time_period.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save CPC as csv\n",
    "pop_keys = outcome_name_supplementary[0:16]\n",
    "\n",
    "tuples = ()\n",
    "index = pd.MultiIndex.from_tuples(tuples,names=['principle', 'year'])\n",
    "CPC_total = pd.DataFrame(columns= region_pop_gr.index,index = index)\n",
    "\n",
    "principles = ['egalitarian','sufficitarian','utilitarian','prioritarian']\n",
    "outcomes = [outcomes_ega,outcomes_suf,outcomes_util,outcomes_prio]\n",
    "\n",
    "index_year = 0\n",
    "principle_index =0 \n",
    "\n",
    "for outcome_principle in outcomes:\n",
    "    for year in pop_keys:\n",
    "        length = (len(outcome_principle[year]))\n",
    "        \n",
    "        if principles[principle_index] ==\"utilitarian\":\n",
    "            tuples = [(principles[principle_index],2005+index_year),]*(125*10**3)\n",
    "        else:\n",
    "            tuples = [(principles[principle_index],2005+index_year),]*10**5\n",
    "        index_1 = pd.MultiIndex.from_tuples(tuples, names=['principle', 'year'])\n",
    "        year_df = pd.DataFrame(data =outcome_principle[year], columns= region_pop_gr.index,index=index_1)\n",
    "\n",
    "        index_year = index_year +20\n",
    "        CPC_total = pd.concat([CPC_total,year_df],axis=0)\n",
    "    principle_index = principle_index + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPC_total.to_csv(\"long_term_POP_per_time_period.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get per quintile outputs and save in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save CPC as csv\n",
    "pop_keys = outcome_name_supplementary_quintile[0:16]\n",
    "\n",
    "quintile = 0\n",
    "tupple = []\n",
    "for i in range(0,10):\n",
    "    run = i\n",
    "    if quintile ==5:\n",
    "        quintile = 0\n",
    "    tupple_to_append = ('egal',year,run,quintile)\n",
    "    tupple.append(tupple_to_append)\n",
    "    quintile = quintile + 1\n",
    "    \n",
    "index = pd.MultiIndex.from_tuples(tupple,names=['principle', 'year','run','quintile'])\n",
    "CPC_total = pd.DataFrame(columns= region_pop_gr.index,index = index)\n",
    "\n",
    "principles = ['egalitarian','sufficitarian','utilitarian','prioritarian']\n",
    "outcomes = [outcomes_ega,outcomes_suf,outcomes_util,outcomes_prio]\n",
    "\n",
    "index_year = 0\n",
    "principle_index =0 \n",
    "\n",
    "for principle in principles:\n",
    "    outcome = outcomes[principle_index]\n",
    "    for year in pop_keys:\n",
    "        #set up tupple \n",
    "        quintile = 0\n",
    "        tupple = []\n",
    "\n",
    "        for i in range(0,len(outcome[year])*5):\n",
    "            run = i\n",
    "            \n",
    "            if quintile ==5:\n",
    "                quintile = 0\n",
    "                \n",
    "            tupple_to_append = (principle,year,run,quintile)\n",
    "            tupple.append(tupple_to_append)\n",
    "            quintile = quintile + 1\n",
    "\n",
    "        #build index for dataframe to store results per saved timestep \n",
    "        index = pd.MultiIndex.from_tuples(tupple,names=['principle', 'year','run','quintile'])\n",
    "\n",
    "        CPC_df = pd.DataFrame(data = outcome[year].reshape(-1,data.shape[-1]),columns= region_pop_gr.index,index =index)\n",
    "\n",
    "        CPC_total = pd.concat([CPC_total,CPC_df],axis=0)\n",
    "    principle_index = principle_index + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPC_total.to_csv(\"long_term_CPC_before_damages_per_time_period.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save CPC as csv\n",
    "pop_keys = outcome_name_supplementary_quintile[16:32]\n",
    "\n",
    "quintile = 0\n",
    "tupple = []\n",
    "for i in range(0,10):\n",
    "    run = i\n",
    "    if quintile ==5:\n",
    "        quintile = 0\n",
    "    tupple_to_append = ('egal',year,run,quintile)\n",
    "    tupple.append(tupple_to_append)\n",
    "    quintile = quintile + 1\n",
    "    \n",
    "index = pd.MultiIndex.from_tuples(tupple,names=['principle', 'year','run','quintile'])\n",
    "CPC_total_after = pd.DataFrame(columns= region_pop_gr.index,index = index)\n",
    "\n",
    "principles = ['egalitarian','sufficitarian','utilitarian','prioritarian']\n",
    "outcomes = [outcomes_ega,outcomes_suf,outcomes_util,outcomes_prio]\n",
    "\n",
    "index_year = 0\n",
    "principle_index =0 \n",
    "\n",
    "for principle in principles:\n",
    "    outcome = outcomes[principle_index]\n",
    "    for year in pop_keys:\n",
    "        #set up tupple \n",
    "        quintile = 0\n",
    "        tupple = []\n",
    "\n",
    "        for i in range(0,len(outcome[year])*5):\n",
    "            run = i\n",
    "            \n",
    "            if quintile ==5:\n",
    "                quintile = 0\n",
    "                \n",
    "            tupple_to_append = (principle,year,run,quintile)\n",
    "            tupple.append(tupple_to_append)\n",
    "            quintile = quintile + 1\n",
    "\n",
    "        #build index for dataframe to store results per saved timestep \n",
    "        index = pd.MultiIndex.from_tuples(tupple,names=['principle', 'year','run','quintile'])\n",
    "\n",
    "        CPC_df = pd.DataFrame(data = outcome[year].reshape(-1,data.shape[-1]),columns= region_pop_gr.index,index =index)\n",
    "\n",
    "        CPC_total_after = pd.concat([CPC_total,CPC_df],axis=0)\n",
    "    principle_index = principle_index + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPC_total_after.to_csv(\"long_term_CPC_after_damages_per_time_period.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
